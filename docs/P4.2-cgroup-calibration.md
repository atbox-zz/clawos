# P4.2: cgroup Resource Value Calibration (Benchmark) Strategy

**Document ID:** P4.2-cgroup-calibration
**Status:** DRAFT
**Created:** 2026-02-24
**Author:** Infra Agent
**Related Specs:** P1.5-cgroup-quotas, SKILLS.md (line 352)

---

## Executive Summary

This document defines the systematic approach for calibrating cgroup v2 resource limits through empirical benchmarking. The strategy ensures optimal resource allocation for all ClawOS components while maintaining ≥80% of IronClaw baseline performance.

**Key Objectives:**
- Establish benchmarking methodology for cgroup limits
- Document performance metrics collection procedures
- Specify tuning strategies for memory, CPU, PIDs, and I/O weights
- Define load testing procedures for each component
- Include OOM behavior testing and recovery validation
- Document calibration iteration process for continuous optimization
- Define target performance baselines (≥80% IronClaw baseline)

---

## 1. Benchmarking Methodology

### 1.1 Prerequisites

**Required Tools:**
```bash
# Install benchmarking tools
sudo apt-get install \
  stress-ng \
  perf \
  sysstat \
  iotop \
  numactl \
  jq \
  bc

# Verify cgroup v2 support
mount | grep cgroup2
cat /proc/cgroups | grep memory

# Verify kernel version (≥6.6 LTS required)
uname -r
```

**Environment Setup:**
```bash
# Create calibration directory
mkdir -p /tmp/cgroup-calibration/{raw,processed,reports,configs}

# Set environment variables for calibration
export CALIBRATION_DURATION=300  # 5 minutes per test
export CALIBRATION_WARMUP=30     # 30 seconds warmup
export CALIBRATION_ITERATIONS=3  # 3 iterations per test
export TARGET_BASELINE=80        # 80% of IronClaw baseline
```

### 1.2 Baseline Establishment

#### 1.2.1 IronClaw Baseline Measurement

```bash
#!/bin/bash
# measure_baseline.sh - Establish IronClaw baseline performance

echo "=== Establishing IronClaw Baseline ==="

# Test 1: Cold start performance
echo "Test 1: Cold start..."
for i in $(seq 1 $CALIBRATION_ITERATIONS); do
  time ./target/release/ironclaw --init 2>&1 | tee -a /tmp/cgroup-calibration/raw/baseline_cold_start_$i.log
done

# Test 2: Normal operation throughput
echo "Test 2: Normal operation..."
for i in $(seq 1 $CALIBRATION_ITERATIONS); do
  perf stat -e cycles,instructions,cache-references,cache-misses,branch-misses \
    -o /tmp/cgroup-calibration/raw/baseline_normal_perf_$i.log \
    ./target/release/ironclaw --run-workload --duration=$CALIBRATION_DURATION
done

# Test 3: Memory usage profile
echo "Test 3: Memory profile..."
for i in $(seq 1 $CALIBRATION_ITERATIONS); do
  ./target/release/ironclaw --run-workload --duration=$CALIBRATION_DURATION &
  PID=$!
  sleep $CALIBRATION_WARMUP
  ps -p $PID -o rss,vsz,pcpu,pmem > /tmp/cgroup-calibration/raw/baseline_memory_$i.log
  kill $PID
done

# Test 4: CPU utilization
echo "Test 4: CPU utilization..."
for i in $(seq 1 $CALIBRATION_ITERATIONS); do
  ./target/release/ironclaw --run-workload --duration=$CALIBRATION_DURATION &
  PID=$!
  sleep $CALIBRATION_WARMUP
  pidstat -p $PID 1 $CALIBRATION_DURATION > /tmp/cgroup-calibration/raw/baseline_cpu_$i.log
  kill $PID
done

# Test 5: I/O throughput
echo "Test 5: I/O throughput..."
for i in $(seq 1 $CALIBRATION_ITERATIONS); do
  ./target/release/ironclaw --run-workload --duration=$CALIBRATION_DURATION &
  PID=$!
  sleep $CALIBRATION_WARMUP
  iotop -p $PID -n -b -o -d 1 > /tmp/cgroup-calibration/raw/baseline_io_$i.log
  kill $PID
done

echo "=== Baseline Measurement Complete ==="
```

#### 1.2.2 Baseline Metrics Aggregation

```bash
#!/bin/bash
# aggregate_baseline.sh - Aggregate baseline metrics

echo "=== Aggregating Baseline Metrics ==="

# Calculate average cold start time
avg_cold_start=$(awk '/real/ {sum+=$2; count++} END {print sum/count}' \
  /tmp/cgroup-calibration/raw/baseline_cold_start_*.log)
echo "Average cold start: ${avg_cold_start}s" > /tmp/cgroup-calibration/processed/baseline_summary.txt

# Calculate average throughput
avg_throughput=$(awk '/throughput/ {sum+=$2; count++} END {print sum/count}' \
  /tmp/cgroup-calibration/raw/baseline_normal_perf_*.log)
echo "Average throughput: ${avg_throughput} req/s" >> /tmp/cgroup-calibration/processed/baseline_summary.txt

# Calculate average memory usage
avg_memory=$(awk '{sum+=$1; count++} END {print sum/count}' \
  /tmp/cgroup-calibration/raw/baseline_memory_*.log)
echo "Average memory: ${avg_memory} KB" >> /tmp/cgroup-calibration/processed/baseline_summary.txt

# Calculate average CPU utilization
avg_cpu=$(awk '{sum+=$3; count++} END {print sum/count}' \
  /tmp/cgroup-calibration/raw/baseline_cpu_*.log)
echo "Average CPU: ${avg_cpu}%" >> /tmp/cgroup-calibration/processed/baseline_summary.txt

# Calculate average I/O throughput
avg_io=$(awk '{sum+=$7; count++} END {print sum/count}' \
  /tmp/cgroup-calibration/raw/baseline_io_*.log)
echo "Average I/O: ${avg_io} KB/s" >> /tmp/cgroup-calibration/processed/baseline_summary.txt

echo "=== Baseline Aggregation Complete ==="
cat /tmp/cgroup-calibration/processed/baseline_summary.txt
```

### 1.3 Calibration Test Matrix

| Component          | Test Scenarios                                            | Duration | Iterations |
| -------------------| ----------------------------------------------------------| ---------| -----------|
| **Agent Loop**     | Cold start, normal ops, high load, error handling         | 300s     | 3          |
| **Worker Pool**    | Single worker, 4 workers, 8 workers, burst load           | 300s     | 3          |
| **WASM Sandbox**   | Single instance, 4 instances, 16 instances, memory stress | 300s     | 3          |
| **eBPF Agent**     | Cold start, event processing, high event rate             | 300s     | 3          |
| **ClawFS Daemon**  | Cold start, read workload, write workload, mixed workload | 300s     | 3          |
| **Security Agent** | Cold start, seccomp enforcement, high syscall rate        | 300s     | 3          |
| **Router**         | Cold start, request routing, high QPS, connection pooling | 300s     | 3          |
| **Orchestrator**   | Cold start, namespace creation, high concurrency          | 300s     | 3          |

---

## 2. Performance Metrics Collection

### 2.1 Memory Metrics

#### 2.1.1 Memory Usage Tracking

```bash
#!/bin/bash
# collect_memory_metrics.sh - Collect memory metrics for cgroup

CGROUP_PATH=$1
OUTPUT_FILE=$2

echo "timestamp,memory_current,memory_max,memory_swap_current,memory_swap_max,oom_events" > $OUTPUT_FILE

for i in $(seq 1 $((CALIBRATION_DURATION / 5))); do
  timestamp=$(date +%s)

  memory_current=$(cat $CGROUP_PATH/memory.current)
  memory_max=$(cat $CGROUP_PATH/memory.max)
|  |
  memory_swap_max=$(cat $CGROUP_PATH/memory.swap.max)
  oom_events=$(cat $CGROUP_PATH/memory.oom_events)

  echo "$timestamp,$memory_current,$memory_max,$memory_swap_current,$memory_swap_max,$oom_events" >> $OUTPUT_FILE

  sleep 5
done
```

#### 2.1.2 Memory Pressure Metrics

```bash
#!/bin/bash
# collect_memory_pressure.sh - Collect memory pressure metrics

CGROUP_PATH=$1
OUTPUT_FILE=$2

echo "timestamp,pressure_some_avg60,pressure_some_avg300,pressure_some_avg600,pressure_full_avg60,pressure_full_avg300,pressure_full_avg600" > $OUTPUT_FILE

for i in $(seq 1 $((CALIBRATION_DURATION / 5))); do
  timestamp=$(date +%s)

  pressure_some=$(cat $CGROUP_PATH/memory.pressure)
|  |

| grep "some avg60="  | cut -d'=' -f2 |
| grep "some avg300=" | cut -d'=' -f2 |
| grep "some avg600=" | cut -d'=' -f2 |

| grep "full avg60="  | cut -d'=' -f2 |
| grep "full avg300=" | cut -d'=' -f2 |
| grep "full avg600=" | cut -d'=' -f2 |

  echo "$timestamp,$some_avg60,$some_avg300,$some_avg600,$full_avg60,$full_avg300,$full_avg600" >> $OUTPUT_FILE

  sleep 5
done
```

### 2.2 CPU Metrics

#### 2.2.1 CPU Usage Tracking

```bash
#!/bin/bash
# collect_cpu_metrics.sh - Collect CPU metrics for cgroup

CGROUP_PATH=$1
OUTPUT_FILE=$2

echo "timestamp,usage_usec,user_usec,system_usec,nr_periods,nr_throttled,throttled_usec" > $OUTPUT_FILE

for i in $(seq 1 $((CALIBRATION_DURATION / 5))); do
  timestamp=$(date +%s)

  cpu_stat=$(cat $CGROUP_PATH/cpu.stat)

| grep "usage_usec"     |
| grep "user_usec"      |
| grep "system_usec"    |
| grep "nr_periods"     |
| grep "nr_throttled"   |
| grep "throttled_usec" |

  echo "$timestamp,$usage_usec,$user_usec,$system_usec,$nr_periods,$nr_throttled,$throttled_usec" >> $OUTPUT_FILE

  sleep 5
done
```

#### 2.2.2 CPU Latency Metrics

```bash
#!/bin/bash
# collect_cpu_latency.sh - Collect CPU latency metrics

CGROUP_PATH=$1
OUTPUT_FILE=$2

echo "timestamp,nr_latencies,latency_avg_usec,latency_max_usec" > $OUTPUT_FILE

for i in $(seq 1 $((CALIBRATION_DURATION / 5))); do
  timestamp=$(date +%s)

  cpu_stat=$(cat $CGROUP_PATH/cpu.stat)

| grep "nr_latencies"     |
| grep "latency_avg_usec" |
| grep "latency_max_usec" |

  echo "$timestamp,$nr_latencies,$latency_avg_usec,$latency_max_usec" >> $OUTPUT_FILE

  sleep 5
done
```

### 2.3 PIDs Metrics

```bash
#!/bin/bash
# collect_pids_metrics.sh - Collect PIDs metrics for cgroup

CGROUP_PATH=$1
OUTPUT_FILE=$2

echo "timestamp,pids_current,pids_max" > $OUTPUT_FILE

for i in $(seq 1 $((CALIBRATION_DURATION / 5))); do
  timestamp=$(date +%s)

  pids_current=$(cat $CGROUP_PATH/pids.current)
  pids_max=$(cat $CGROUP_PATH/pids.max)

  echo "$timestamp,$pids_current,$pids_max" >> $OUTPUT_FILE

  sleep 5
done
```

### 2.4 I/O Metrics

```bash
#!/bin/bash
# collect_io_metrics.sh - Collect I/O metrics for cgroup

CGROUP_PATH=$1
OUTPUT_FILE=$2

echo "timestamp,rbytes,wbytes,rios,wios,dbytes,dios" > $OUTPUT_FILE

for i in $(seq 1 $((CALIBRATION_DURATION / 5))); do
  timestamp=$(date +%s)

  io_stat=$(cat $CGROUP_PATH/io.stat)

| grep "rbytes=" | cut -d'=' -f2 |
| grep "wbytes=" | cut -d'=' -f2 |
| grep "rios="   | cut -d'=' -f2 |
| grep "wios="   | cut -d'=' -f2 |
| grep "dbytes=" | cut -d'=' -f2 |
| grep "dios="   | cut -d'=' -f2 |

  echo "$timestamp,$rbytes,$wbytes,$rios,$wios,$dbytes,$dios" >> $OUTPUT_FILE

  sleep 5
done
```

---

## 3. Resource Tuning Strategies

### 3.1 Memory Tuning

#### 3.1.1 Memory Limit Calibration

**Calibration Algorithm:**
```
START: memory.max = P1.5 baseline value
  │
  ├─ Run workload for CALIBRATION_DURATION
  │   ├─ Collect memory metrics
  │   └─ Calculate memory efficiency
  │
  ├─ Is memory efficiency ≥ TARGET_BASELINE?
  │   ├─ YES → Check memory pressure
  │   │   ├─ Is pressure_some_avg60 < 1%?
  │   │   │   ├─ YES → Try reducing memory.max by 10%
  │   │   │   └─ NO  → Keep current limit
  │   │   └─ Is pressure_full_avg60 < 0.1%?
  │   │       ├─ YES → Try reducing memory.max by 5%
  │   │       └─ NO  → Keep current limit
  │   │
  │   └─ NO → Increase memory.max by 20%
  │
  └─ Repeat until convergence (±5%)
```

**Memory Efficiency Formula:**
```
memory_efficiency = (throughput / memory_max) * 100

Target: memory_efficiency ≥ 80% of baseline
```

#### 3.1.2 Memory Tuning Script

```bash
#!/bin/bash
# tune_memory.sh - Calibrate memory limits

CGROUP_PATH=$1
COMPONENT=$2
BASELINE_MEMORY=$3

echo "=== Calibrating Memory for $COMPONENT ==="

current_memory=$BASELINE_MEMORY
iteration=0
max_iterations=10

while [ $iteration -lt $max_iterations ]; do
  echo "Iteration $iteration: Testing memory.max = $current_memory"

  # Apply memory limit
  echo $current_memory > $CGROUP_PATH/memory.max

  # Run workload
  ./target/release/ironclaw --run-workload --component=$COMPONENT --duration=$CALIBRATION_DURATION &
  PID=$!
  sleep $CALIBRATION_WARMUP

  # Collect metrics
  collect_memory_metrics.sh $CGROUP_PATH /tmp/cgroup-calibration/raw/memory_${COMPONENT}_${iteration}.csv &
  METRIC_PID=$!

  # Wait for workload
  wait $PID
  kill $METRIC_PID 2>/dev/null

  # Calculate efficiency
  avg_memory=$(awk -F',' 'NR>1 {sum+=$2; count++} END {print sum/count}' \
    /tmp/cgroup-calibration/raw/memory_${COMPONENT}_${iteration}.csv)

  efficiency=$(echo "scale=2; ($avg_memory / $current_memory) * 100" | bc)
  echo "Memory efficiency: $efficiency%"

  # Check pressure
  pressure_some=$(awk -F',' 'NR>1 {sum+=$2; count++} END {print sum/count}' \
|  |

  # Decision
  if (( $(echo "$efficiency >= $TARGET_BASELINE" | bc -l) )); then
    if (( $(echo "$pressure_some < 1.0" | bc -l) )); then
      # Try reducing memory
      current_memory=$(echo "$current_memory * 0.9 / 1" | bc)
      current_memory=${current_memory%.*}
    else
      # Keep current limit
      break
    fi
  else
    # Increase memory
    current_memory=$(echo "$current_memory * 1.2 / 1" | bc)
    current_memory=${current_memory%.*}
  fi

  iteration=$((iteration + 1))
done

echo "=== Memory Calibration Complete ==="
echo "Optimal memory.max for $COMPONENT: $current_memory"
echo $current_memory > /tmp/cgroup-calibration/processed/${COMPONENT}_memory_optimal.txt
```

### 3.2 CPU Tuning

#### 3.2.1 CPU Quota Calibration

**Calibration Algorithm:**
```
START: cpu.max = P1.5 baseline value
  │
  ├─ Run workload for CALIBRATION_DURATION
  │   ├─ Collect CPU metrics
  │   └─ Calculate CPU efficiency
  │
  ├─ Is CPU efficiency ≥ TARGET_BASELINE?
  │   ├─ YES → Check throttling
  │   │   ├─ Is nr_throttled < 1% of nr_periods?
  │   │   │   ├─ YES → Try reducing cpu.max by 10%
  │   │   │   └─ NO  → Keep current quota
  │   │   └─ Is throttled_usec < 1% of usage_usec?
  │   │       ├─ YES → Try reducing cpu.max by 5%
  │   │       └─ NO  → Keep current quota
  │   │
  │   └─ NO → Increase cpu.max by 20%
  │
  └─ Repeat until convergence (±5%)
```

**CPU Efficiency Formula:**
```
cpu_efficiency = (throughput / cpu_quota) * 100

Target: cpu_efficiency ≥ 80% of baseline
```

#### 3.2.2 CPU Tuning Script

```bash
#!/bin/bash
# tune_cpu.sh - Calibrate CPU quotas

CGROUP_PATH=$1
COMPONENT=$2
BASELINE_CPU_QUOTA=$3
CPU_PERIOD=1000000

echo "=== Calibrating CPU for $COMPONENT ==="

current_quota=$BASELINE_CPU_QUOTA
iteration=0
max_iterations=10

while [ $iteration -lt $max_iterations ]; do
  echo "Iteration $iteration: Testing cpu.max = $current_quota $CPU_PERIOD"

  # Apply CPU quota
  echo "$current_quota $CPU_PERIOD" > $CGROUP_PATH/cpu.max

  # Run workload
  ./target/release/ironclaw --run-workload --component=$COMPONENT --duration=$CALIBRATION_DURATION &
  PID=$!
  sleep $CALIBRATION_WARMUP

  # Collect metrics
  collect_cpu_metrics.sh $CGROUP_PATH /tmp/cgroup-calibration/raw/cpu_${COMPONENT}_${iteration}.csv &
  METRIC_PID=$!

  # Wait for workload
  wait $PID
  kill $METRIC_PID 2>/dev/null

  # Calculate efficiency
  avg_usage=$(awk -F',' 'NR>1 {sum+=$2; count++} END {print sum/count}' \
    /tmp/cgroup-calibration/raw/cpu_${COMPONENT}_${iteration}.csv)

  efficiency=$(echo "scale=2; ($avg_usage / ($current_quota * $CALIBRATION_DURATION)) * 100" | bc)
  echo "CPU efficiency: $efficiency%"

  # Check throttling
  nr_periods=$(tail -1 /tmp/cgroup-calibration/raw/cpu_${COMPONENT}_${iteration}.csv | cut -d',' -f5)
  nr_throttled=$(tail -1 /tmp/cgroup-calibration/raw/cpu_${COMPONENT}_${iteration}.csv | cut -d',' -f6)
  throttled_usec=$(tail -1 /tmp/cgroup-calibration/raw/cpu_${COMPONENT}_${iteration}.csv | cut -d',' -f7)

  throttling_ratio=$(echo "scale=4; $nr_throttled / $nr_periods * 100" | bc)
  echo "Throttling ratio: $throttling_ratio%"

  # Decision
  if (( $(echo "$efficiency >= $TARGET_BASELINE" | bc -l) )); then
    if (( $(echo "$throttling_ratio < 1.0" | bc -l) )); then
      # Try reducing quota
      current_quota=$(echo "$current_quota * 0.9 / 1" | bc)
      current_quota=${current_quota%.*}
    else
      # Keep current quota
      break
    fi
  else
    # Increase quota
    current_quota=$(echo "$current_quota * 1.2 / 1" | bc)
    current_quota=${current_quota%.*}
  fi

  iteration=$((iteration + 1))
done

echo "=== CPU Calibration Complete ==="
echo "Optimal cpu.max for $COMPONENT: $current_quota $CPU_PERIOD"
echo "$current_quota $CPU_PERIOD" > /tmp/cgroup-calibration/processed/${COMPONENT}_cpu_optimal.txt
```

### 3.3 PIDs Tuning

#### 3.3.1 PIDs Limit Calibration

**Calibration Algorithm:**
```
START: pids.max = P1.5 baseline value
  │
  ├─ Run workload for CALIBRATION_DURATION
  │   ├─ Collect PIDs metrics
  │   └─ Calculate PIDs utilization
  │
  ├─ Is PIDs utilization < 80%?
  │   ├─ YES → Try reducing pids.max by 10%
  │   └─ NO  → Keep current limit
  │
  ├─ Is PIDs utilization > 90%?
  │   ├─ YES → Increase pids.max by 20%
  │   └─ NO  → Keep current limit
  │
  └─ Repeat until convergence (±5%)
```

**PIDs Utilization Formula:**
```
pids_utilization = (pids_current / pids_max) * 100

Target: 70% ≤ pids_utilization ≤ 85%
```

#### 3.3.2 PIDs Tuning Script

```bash
#!/bin/bash
# tune_pids.sh - Calibrate PIDs limits

CGROUP_PATH=$1
COMPONENT=$2
BASELINE_PIDS=$3

echo "=== Calibrating PIDs for $COMPONENT ==="

current_pids=$BASELINE_PIDS
iteration=0
max_iterations=10

while [ $iteration -lt $max_iterations ]; do
  echo "Iteration $iteration: Testing pids.max = $current_pids"

  # Apply PIDs limit
  echo $current_pids > $CGROUP_PATH/pids.max

  # Run workload
  ./target/release/ironclaw --run-workload --component=$COMPONENT --duration=$CALIBRATION_DURATION &
  PID=$!
  sleep $CALIBRATION_WARMUP

  # Collect metrics
  collect_pids_metrics.sh $CGROUP_PATH /tmp/cgroup-calibration/raw/pids_${COMPONENT}_${iteration}.csv &
  METRIC_PID=$!

  # Wait for workload
  wait $PID
  kill $METRIC_PID 2>/dev/null

  # Calculate utilization
  max_pids=$(awk -F',' 'NR>1 {if($2>max) max=$2} END {print max}' \
    /tmp/cgroup-calibration/raw/pids_${COMPONENT}_${iteration}.csv)

  utilization=$(echo "scale=2; ($max_pids / $current_pids) * 100" | bc)
  echo "PIDs utilization: $utilization%"

  # Decision
  if (( $(echo "$utilization < 80.0" | bc -l) )); then
    # Try reducing limit
    current_pids=$(echo "$current_pids * 0.9 / 1" | bc)
    current_pids=${current_pids%.*}
  elif (( $(echo "$utilization > 90.0" | bc -l) )); then
    # Increase limit
    current_pids=$(echo "$current_pids * 1.2 / 1" | bc)
    current_pids=${current_pids%.*}
  else
    # Keep current limit
    break
  fi

  iteration=$((iteration + 1))
done

echo "=== PIDs Calibration Complete ==="
echo "Optimal pids.max for $COMPONENT: $current_pids"
echo $current_pids > /tmp/cgroup-calibration/processed/${COMPONENT}_pids_optimal.txt
```

### 3.4 I/O Weight Tuning

#### 3.4.1 I/O Weight Calibration

**Calibration Algorithm:**
```
START: io.weight = P1.5 baseline value
  │
  ├─ Run workload for CALIBRATION_DURATION
  │   ├─ Collect I/O metrics
  │   └─ Calculate I/O throughput
  │
  ├─ Is I/O throughput ≥ TARGET_BASELINE?
  │   ├─ YES → Check I/O latency
  │   │   ├─ Is I/O latency < baseline latency * 1.1?
  │   │   │   ├─ YES → Try reducing io.weight by 10%
  │   │   │   └─ NO  → Keep current weight
  │   │   └─ Is I/O latency < baseline latency * 1.2?
  │   │       ├─ YES → Try reducing io.weight by 5%
  │   │       └─ NO  → Keep current weight
  │   │
  │   └─ NO → Increase io.weight by 20%
  │
  └─ Repeat until convergence (±5%)
```

**I/O Throughput Formula:**
```
io_throughput = (rbytes + wbytes) / duration

Target: io_throughput ≥ 80% of baseline
```

#### 3.4.2 I/O Weight Tuning Script

```bash
#!/bin/bash
# tune_io.sh - Calibrate I/O weights

CGROUP_PATH=$1
COMPONENT=$2
BASELINE_IO_WEIGHT=$3
BASELINE_IO_THROUGHPUT=$4

echo "=== Calibrating I/O for $COMPONENT ==="

current_weight=$BASELINE_IO_WEIGHT
iteration=0
max_iterations=10

while [ $iteration -lt $max_iterations ]; do
  echo "Iteration $iteration: Testing io.weight = $current_weight"

  # Apply I/O weight
  echo $current_weight > $CGROUP_PATH/io.weight

  # Run workload
  ./target/release/ironclaw --run-workload --component=$COMPONENT --duration=$CALIBRATION_DURATION &
  PID=$!
  sleep $CALIBRATION_WARMUP

  # Collect metrics
  collect_io_metrics.sh $CGROUP_PATH /tmp/cgroup-calibration/raw/io_${COMPONENT}_${iteration}.csv &
  METRIC_PID=$!

  # Wait for workload
  wait $PID
  kill $METRIC_PID 2>/dev/null

  # Calculate throughput
| tail -1 |
|  |
| tail -1 |
|  |

  total_bytes=$((last_rbytes - first_rbytes + last_wbytes - first_wbytes))
  throughput=$(echo "scale=2; $total_bytes / $CALIBRATION_DURATION" | bc)
  echo "I/O throughput: $throughput bytes/s"

  throughput_ratio=$(echo "scale=2; ($throughput / $BASELINE_IO_THROUGHPUT) * 100" | bc)
  echo "Throughput ratio: $throughput_ratio%"

  # Decision
  if (( $(echo "$throughput_ratio >= $TARGET_BASELINE" | bc -l) )); then
    # Try reducing weight
    current_weight=$(echo "$current_weight * 0.9 / 1" | bc)
    current_weight=${current_weight%.*}
  else
    # Increase weight
    current_weight=$(echo "$current_weight * 1.2 / 1" | bc)
    current_weight=${current_weight%.*}
  fi

  iteration=$((iteration + 1))
done

echo "=== I/O Calibration Complete ==="
echo "Optimal io.weight for $COMPONENT: $current_weight"
echo $current_weight > /tmp/cgroup-calibration/processed/${COMPONENT}_io_optimal.txt
```

---

## 4. Load Testing Procedures

### 4.1 Agent Loop Load Testing

```bash
#!/bin/bash
# load_test_agent_loop.sh - Load test Agent Loop

CGROUP_PATH="/sys/fs/cgroup/clawos/agents.slice/agent-loop"
COMPONENT="agent-loop"

echo "=== Load Testing Agent Loop ==="

# Test 1: Normal load (baseline)
echo "Test 1: Normal load..."
./target/release/ironclaw --run-workload --component=$COMPONENT \
  --duration=$CALIBRATION_DURATION --concurrent-tasks=10 &
PID=$!
sleep $CALIBRATION_WARMUP

collect_memory_metrics.sh $CGROUP_PATH /tmp/cgroup-calibration/raw/${COMPONENT}_normal_memory.csv &
collect_cpu_metrics.sh $CGROUP_PATH /tmp/cgroup-calibration/raw/${COMPONENT}_normal_cpu.csv &
collect_pids_metrics.sh $CGROUP_PATH /tmp/cgroup-calibration/raw/${COMPONENT}_normal_pids.csv &

wait $PID
killall collect_memory_metrics.sh collect_cpu_metrics.sh collect_pids_metrics.sh 2>/dev/null

# Test 2: High load (2x baseline)
echo "Test 2: High load..."
./target/release/ironclaw --run-workload --component=$COMPONENT \
  --duration=$CALIBRATION_DURATION --concurrent-tasks=20 &
PID=$!
sleep $CALIBRATION_WARMUP

collect_memory_metrics.sh $CGROUP_PATH /tmp/cgroup-calibration/raw/${COMPONENT}_high_memory.csv &
collect_cpu_metrics.sh $CGROUP_PATH /tmp/cgroup-calibration/raw/${COMPONENT}_high_cpu.csv &
collect_pids_metrics.sh $CGROUP_PATH /tmp/cgroup-calibration/raw/${COMPONENT}_high_pids.csv &

wait $PID
killall collect_memory_metrics.sh collect_cpu_metrics.sh collect_pids_metrics.sh 2>/dev/null

# Test 3: Burst load (5x baseline for 30s)
echo "Test 3: Burst load..."
./target/release/ironclaw --run-workload --component=$COMPONENT \
  --duration=30 --concurrent-tasks=50 &
PID=$!
sleep 5

collect_memory_metrics.sh $CGROUP_PATH /tmp/cgroup-calibration/raw/${COMPONENT}_burst_memory.csv &
collect_cpu_metrics.sh $CGROUP_PATH /tmp/cgroup-calibration/raw/${COMPONENT}_burst_cpu.csv &
collect_pids_metrics.sh $CGROUP_PATH /tmp/cgroup-calibration/raw/${COMPONENT}_burst_pids.csv &

wait $PID
killall collect_memory_metrics.sh collect_cpu_metrics.sh collect_pids_metrics.sh 2>/dev/null

echo "=== Agent Loop Load Testing Complete ==="
```

### 4.2 Worker Pool Load Testing

```bash
#!/bin/bash
# load_test_worker_pool.sh - Load test Worker Pool

CGROUP_PATH="/sys/fs/cgroup/clawos/worker.slice"
COMPONENT="worker-pool"

echo "=== Load Testing Worker Pool ==="

# Test 1: Single worker
echo "Test 1: Single worker..."
./target/release/ironclaw --run-workload --component=$COMPONENT \
  --duration=$CALIBRATION_DURATION --workers=1 &
PID=$!
sleep $CALIBRATION_WARMUP

collect_memory_metrics.sh $CGROUP_PATH /tmp/cgroup-calibration/raw/${COMPONENT}_1w_memory.csv &
collect_cpu_metrics.sh $CGROUP_PATH /tmp/cgroup-calibration/raw/${COMPONENT}_1w_cpu.csv &
collect_pids_metrics.sh $CGROUP_PATH /tmp/cgroup-calibration/raw/${COMPONENT}_1w_pids.csv &

wait $PID
killall collect_memory_metrics.sh collect_cpu_metrics.sh collect_pids_metrics.sh 2>/dev/null

# Test 2: 4 workers
echo "Test 2: 4 workers..."
./target/release/ironclaw --run-workload --component=$COMPONENT \
  --duration=$CALIBRATION_DURATION --workers=4 &
PID=$!
sleep $CALIBRATION_WARMUP

collect_memory_metrics.sh $CGROUP_PATH /tmp/cgroup-calibration/raw/${COMPONENT}_4w_memory.csv &
collect_cpu_metrics.sh $CGROUP_PATH /tmp/cgroup-calibration/raw/${COMPONENT}_4w_cpu.csv &
collect_pids_metrics.sh $CGROUP_PATH /tmp/cgroup-calibration/raw/${COMPONENT}_4w_pids.csv &

wait $PID
killall collect_memory_metrics.sh collect_cpu_metrics.sh collect_pids_metrics.sh 2>/dev/null

# Test 3: 8 workers (max)
echo "Test 3: 8 workers..."
./target/release/ironclaw --run-workload --component=$COMPONENT \
  --duration=$CALIBRATION_DURATION --workers=8 &
PID=$!
sleep $CALIBRATION_WARMUP

collect_memory_metrics.sh $CGROUP_PATH /tmp/cgroup-calibration/raw/${COMPONENT}_8w_memory.csv &
collect_cpu_metrics.sh $CGROUP_PATH /tmp/cgroup-calibration/raw/${COMPONENT}_8w_cpu.csv &
collect_pids_metrics.sh $CGROUP_PATH /tmp/cgroup-calibration/raw/${COMPONENT}_8w_pids.csv &

wait $PID
killall collect_memory_metrics.sh collect_cpu_metrics.sh collect_pids_metrics.sh 2>/dev/null

echo "=== Worker Pool Load Testing Complete ==="
```

### 4.3 WASM Sandbox Load Testing

```bash
#!/bin/bash
# load_test_wasm_sandbox.sh - Load test WASM Sandbox

CGROUP_PATH="/sys/fs/cgroup/clawos/wasm.slice"
COMPONENT="wasm-sandbox"

echo "=== Load Testing WASM Sandbox ==="

# Test 1: Single instance
echo "Test 1: Single instance..."
./target/release/ironclaw --run-wasm-tool --component=$COMPONENT \
  --duration=$CALIBRATION_DURATION --instances=1 &
PID=$!
sleep $CALIBRATION_WARMUP

collect_memory_metrics.sh $CGROUP_PATH /tmp/cgroup-calibration/raw/${COMPONENT}_1i_memory.csv &
collect_cpu_metrics.sh $CGROUP_PATH /tmp/cgroup-calibration/raw/${COMPONENT}_1i_cpu.csv &
collect_pids_metrics.sh $CGROUP_PATH /tmp/cgroup-calibration/raw/${COMPONENT}_1i_pids.csv &

wait $PID
killall collect_memory_metrics.sh collect_cpu_metrics.sh collect_pids_metrics.sh 2>/dev/null

# Test 2: 4 instances
echo "Test 2: 4 instances..."
./target/release/ironclaw --run-wasm-tool --component=$COMPONENT \
  --duration=$CALIBRATION_DURATION --instances=4 &
PID=$!
sleep $CALIBRATION_WARMUP

collect_memory_metrics.sh $CGROUP_PATH /tmp/cgroup-calibration/raw/${COMPONENT}_4i_memory.csv &
collect_cpu_metrics.sh $CGROUP_PATH /tmp/cgroup-calibration/raw/${COMPONENT}_4i_cpu.csv &
collect_pids_metrics.sh $CGROUP_PATH /tmp/cgroup-calibration/raw/${COMPONENT}_4i_pids.csv &

wait $PID
killall collect_memory_metrics.sh collect_cpu_metrics.sh collect_pids_metrics.sh 2>/dev/null

# Test 3: 16 instances (max)
echo "Test 3: 16 instances..."
./target/release/ironclaw --run-wasm-tool --component=$COMPONENT \
  --duration=$CALIBRATION_DURATION --instances=16 &
PID=$!
sleep $CALIBRATION_WARMUP

collect_memory_metrics.sh $CGROUP_PATH /tmp/cgroup-calibration/raw/${COMPONENT}_16i_memory.csv &
collect_cpu_metrics.sh $CGROUP_PATH /tmp/cgroup-calibration/raw/${COMPONENT}_16i_cpu.csv &
collect_pids_metrics.sh $CGROUP_PATH /tmp/cgroup-calibration/raw/${COMPONENT}_16i_pids.csv &

wait $PID
killall collect_memory_metrics.sh collect_cpu_metrics.sh collect_pids_metrics.sh 2>/dev/null

# Test 4: Memory stress (single instance, allocate 90% of limit)
echo "Test 4: Memory stress..."
./target/release/ironclaw --run-wasm-tool --component=$COMPONENT \
  --duration=$CALIBRATION_DURATION --instances=1 --memory-stress=90 &
PID=$!
sleep $CALIBRATION_WARMUP

collect_memory_metrics.sh $CGROUP_PATH /tmp/cgroup-calibration/raw/${COMPONENT}_stress_memory.csv &
collect_memory_pressure.sh $CGROUP_PATH /tmp/cgroup-calibration/raw/${COMPONENT}_stress_pressure.csv &

wait $PID
killall collect_memory_metrics.sh collect_memory_pressure.sh 2>/dev/null

echo "=== WASM Sandbox Load Testing Complete ==="
```

### 4.4 eBPF Agent Load Testing

```bash
#!/bin/bash
# load_test_ebpf_agent.sh - Load test eBPF Agent

CGROUP_PATH="/sys/fs/cgroup/clawos/kernel.slice/ebpf-agent"
COMPONENT="ebpf-agent"

echo "=== Load Testing eBPF Agent ==="

# Test 1: Normal event rate (baseline)
echo "Test 1: Normal event rate..."
./target/release/ironclaw --run-workload --component=$COMPONENT \
  --duration=$CALIBRATION_DURATION --event-rate=1000 &
PID=$!
sleep $CALIBRATION_WARMUP

collect_memory_metrics.sh $CGROUP_PATH /tmp/cgroup-calibration/raw/${COMPONENT}_normal_memory.csv &
collect_cpu_metrics.sh $CGROUP_PATH /tmp/cgroup-calibration/raw/${COMPONENT}_normal_cpu.csv &

wait $PID
killall collect_memory_metrics.sh collect_cpu_metrics.sh 2>/dev/null

# Test 2: High event rate (10x baseline)
echo "Test 2: High event rate..."
./target/release/ironclaw --run-workload --component=$COMPONENT \
  --duration=$CALIBRATION_DURATION --event-rate=10000 &
PID=$!
sleep $CALIBRATION_WARMUP

collect_memory_metrics.sh $CGROUP_PATH /tmp/cgroup-calibration/raw/${COMPONENT}_high_memory.csv &
collect_cpu_metrics.sh $CGROUP_PATH /tmp/cgroup-calibration/raw/${COMPONENT}_high_cpu.csv &

wait $PID
killall collect_memory_metrics.sh collect_cpu_metrics.sh 2>/dev/null

# Test 3: Burst event rate (100x baseline for 30s)
echo "Test 3: Burst event rate..."
./target/release/ironclaw --run-workload --component=$COMPONENT \
  --duration=30 --event-rate=100000 &
PID=$!
sleep 5

collect_memory_metrics.sh $CGROUP_PATH /tmp/cgroup-calibration/raw/${COMPONENT}_burst_memory.csv &
collect_cpu_metrics.sh $CGROUP_PATH /tmp/cgroup-calibration/raw/${COMPONENT}_burst_cpu.csv &

wait $PID
killall collect_memory_metrics.sh collect_cpu_metrics.sh 2>/dev/null

echo "=== eBPF Agent Load Testing Complete ==="
```

### 4.5 ClawFS Daemon Load Testing

```bash
#!/bin/bash
# load_test_clawfs_daemon.sh - Load test ClawFS Daemon

CGROUP_PATH="/sys/fs/cgroup/clawos/kernel.slice/clawfs-daemon"
COMPONENT="clawfs-daemon"

echo "=== Load Testing ClawFS Daemon ==="

# Test 1: Read workload
echo "Test 1: Read workload..."
./target/release/ironclaw --run-workload --component=$COMPONENT \
  --duration=$CALIBRATION_DURATION --workload=read --ops=10000 &
PID=$!
sleep $CALIBRATION_WARMUP

collect_memory_metrics.sh $CGROUP_PATH /tmp/cgroup-calibration/raw/${COMPONENT}_read_memory.csv &
collect_cpu_metrics.sh $CGROUP_PATH /tmp/cgroup-calibration/raw/${COMPONENT}_read_cpu.csv &
collect_io_metrics.sh $CGROUP_PATH /tmp/cgroup-calibration/raw/${COMPONENT}_read_io.csv &

wait $PID
killall collect_memory_metrics.sh collect_cpu_metrics.sh collect_io_metrics.sh 2>/dev/null

# Test 2: Write workload
echo "Test 2: Write workload..."
./target/release/ironclaw --run-workload --component=$COMPONENT \
  --duration=$CALIBRATION_DURATION --workload=write --ops=10000 &
PID=$!
sleep $CALIBRATION_WARMUP

collect_memory_metrics.sh $CGROUP_PATH /tmp/cgroup-calibration/raw/${COMPONENT}_write_memory.csv &
collect_cpu_metrics.sh $CGROUP_PATH /tmp/cgroup-calibration/raw/${COMPONENT}_write_cpu.csv &
collect_io_metrics.sh $CGROUP_PATH /tmp/cgroup-calibration/raw/${COMPONENT}_write_io.csv &

wait $PID
killall collect_memory_metrics.sh collect_cpu_metrics.sh collect_io_metrics.sh 2>/dev/null

# Test 3: Mixed workload (70% read, 30% write)
echo "Test 3: Mixed workload..."
./target/release/ironclaw --run-workload --component=$COMPONENT \
  --duration=$CALIBRATION_DURATION --workload=mixed --ops=10000 --read-ratio=70 &
PID=$!
sleep $CALIBRATION_WARMUP

collect_memory_metrics.sh $CGROUP_PATH /tmp/cgroup-calibration/raw/${COMPONENT}_mixed_memory.csv &
collect_cpu_metrics.sh $CGROUP_PATH /tmp/cgroup-calibration/raw/${COMPONENT}_mixed_cpu.csv &
collect_io_metrics.sh $CGROUP_PATH /tmp/cgroup-calibration/raw/${COMPONENT}_mixed_io.csv &

wait $PID
killall collect_memory_metrics.sh collect_cpu_metrics.sh collect_io_metrics.sh 2>/dev/null

echo "=== ClawFS Daemon Load Testing Complete ==="
```

---

## 5. OOM Behavior Testing

### 5.1 OOM Trigger Testing

```bash
#!/bin/bash
# test_oom_trigger.sh - Test OOM trigger behavior

CGROUP_PATH=$1
COMPONENT=$2
MEMORY_LIMIT=$3

echo "=== Testing OOM Trigger for $COMPONENT ==="

# Apply memory limit
echo $MEMORY_LIMIT > $CGROUP_PATH/memory.max
echo "1" > $CGROUP_PATH/memory.oom.group

# Start workload
./target/release/ironclaw --run-workload --component=$COMPONENT \
  --memory-stress=110 --duration=600 &
PID=$!

# Monitor for OOM
oom_triggered=0
for i in $(seq 1 120); do
  oom_events=$(cat $CGROUP_PATH/memory.oom_events)
  if [ "$oom_events" -gt 0 ]; then
    oom_triggered=1
    echo "OOM triggered at iteration $i"
    break
  fi
  sleep 5
done

# Check if process was killed
if ! kill -0 $PID 2>/dev/null; then
  echo "[✓] Process killed by OOM"
else
  echo "[✗] Process still running after OOM"
  kill $PID
fi

# Verify OOM group behavior
if [ "$oom_triggered" -eq 1 ]; then
  echo "[✓] OOM event detected"
else
  echo "[✗] No OOM event detected"
fi

echo "=== OOM Trigger Test Complete ==="
```

### 5.2 OOM Recovery Testing

```bash
#!/bin/bash
# test_oom_recovery.sh - Test OOM recovery behavior

CGROUP_PATH=$1
COMPONENT=$2
MEMORY_LIMIT=$3

echo "=== Testing OOM Recovery for $COMPONENT ==="

# Apply memory limit
echo $MEMORY_LIMIT > $CGROUP_PATH/memory.max
echo "1" > $CGROUP_PATH/memory.oom.group

# Test 1: Single OOM event
echo "Test 1: Single OOM event..."
./target/release/ironclaw --run-workload --component=$COMPONENT \
  --memory-stress=110 --duration=600 &
PID=$!

# Wait for OOM
sleep 30

# Restart component
systemctl restart clawos-$COMPONENT

# Verify recovery
sleep 10
if systemctl is-active --quiet clawos-$COMPONENT; then
  echo "[✓] Component recovered after OOM"
else
  echo "[✗] Component failed to recover"
fi

# Test 2: Multiple OOM events
echo "Test 2: Multiple OOM events..."
for i in $(seq 1 3); do
  ./target/release/ironclaw --run-workload --component=$COMPONENT \
    --memory-stress=110 --duration=600 &
  PID=$!

  # Wait for OOM
  sleep 30

  # Restart component
  systemctl restart clawos-$COMPONENT

  # Verify recovery
  sleep 10
  if ! systemctl is-active --quiet clawos-$COMPONENT; then
    echo "[✗] Component failed to recover after OOM $i"
    exit 1
  fi
done

echo "[✓] Component recovered after 3 OOM events"

echo "=== OOM Recovery Test Complete ==="
```

### 5.3 OOM Group Kill Testing

```bash
#!/bin/bash
# test_oom_group_kill.sh - Test OOM group kill behavior

CGROUP_PATH=$1
COMPONENT=$2
MEMORY_LIMIT=$3

echo "=== Testing OOM Group Kill for $COMPONENT ==="

# Apply memory limit with OOM group enabled
echo $MEMORY_LIMIT > $CGROUP_PATH/memory.max
echo "1" > $CGROUP_PATH/memory.oom.group

# Start multiple processes in the same cgroup
for i in $(seq 1 5); do
  ./target/release/ironclaw --run-workload --component=$COMPONENT \
    --memory-stress=110 --duration=600 &
  PIDS[$i]=$!
done

# Wait for OOM
sleep 30

# Check if all processes were killed
all_killed=1
for i in $(seq 1 5); do
  if kill -0 ${PIDS[$i]} 2>/dev/null; then
    echo "[✗] Process ${PIDS[$i]} still running after OOM"
    all_killed=0
  fi
done

if [ "$all_killed" -eq 1 ]; then
  echo "[✓] All processes killed by OOM group"
else
  echo "[✗] Not all processes killed by OOM group"
fi

# Test with OOM group disabled
echo "Testing with OOM group disabled..."
echo "0" > $CGROUP_PATH/memory.oom.group

# Start multiple processes
for i in $(seq 1 5); do
  ./target/release/ironclaw --run-workload --component=$COMPONENT \
    --memory-stress=110 --duration=600 &
  PIDS[$i]=$!
done

# Wait for OOM
sleep 30

# Check if only one process was killed
killed_count=0
for i in $(seq 1 5); do
  if ! kill -0 ${PIDS[$i]} 2>/dev/null; then
    killed_count=$((killed_count + 1))
  fi
done

if [ "$killed_count" -eq 1 ]; then
  echo "[✓] Only one process killed (OOM group disabled)"
else
  echo "[✗] Expected 1 process killed, got $killed_count"
fi

echo "=== OOM Group Kill Test Complete ==="
```

---

## 6. Calibration Iteration Process

### 6.1 Iteration Workflow

```
START: P1.5 baseline values
  │
  ├─ Phase 1: Baseline Measurement
  │   ├─ Run all load tests
  │   ├─ Collect metrics
  │   └─ Establish baseline performance
  │
  ├─ Phase 2: Initial Calibration
  │   ├─ Tune memory limits
  │   ├─ Tune CPU quotas
  │   ├─ Tune PIDs limits
  │   └─ Tune I/O weights
  │
  ├─ Phase 3: Validation
  │   ├─ Run all load tests with new values
  │   ├─ Compare performance to baseline
  │   └─ Verify ≥80% baseline performance
  │
  ├─ Phase 4: Iteration Decision
  │   ├─ Is performance ≥80% baseline?
  │   │   ├─ YES → Check for optimization opportunities
  │   │   │   ├─ Can reduce resources further?
  │   │   │   │   ├─ YES → Go to Phase 2
  │   │   │   │   └─ NO  → Go to Phase 5
  │   │   │   └─ Can improve performance?
  │   │   │       ├─ YES → Go to Phase 2
  │   │   │       └─ NO  → Go to Phase 5
  │   │   └─ NO → Increase resources
  │   │       └─ Go to Phase 2
  │
  └─ Phase 5: Finalization
      ├─ Document optimal values
      ├─ Generate calibration report
      └─ Update P1.5 specification
```

### 6.2 Iteration Script

```bash
#!/bin/bash
# run_calibration_iteration.sh - Run single calibration iteration

ITERATION=$1
COMPONENT=$2

echo "=== Calibration Iteration $ITERATION for $COMPONENT ==="

# Phase 1: Load testing
echo "Phase 1: Load testing..."
./scripts/load_test_${COMPONENT}.sh

# Phase 2: Tuning
echo "Phase 2: Tuning..."
| select(.name == \"$COMPONENT\") |

| select(.name == \"$COMPONENT\") |
| select(.name == \"$COMPONENT\") | .resource_limits.cpu.max" specs/p1/P1.5-cgroup-quotas.json |
| select(.name == \"$COMPONENT\") |
| select(.name == \"$COMPONENT\") |

./scripts/tune_memory.sh $CGROUP_PATH $COMPONENT $MEMORY_LIMIT
./scripts/tune_cpu.sh $CGROUP_PATH $COMPONENT $CPU_QUOTA
./scripts/tune_pids.sh $CGROUP_PATH $COMPONENT $PIDS_LIMIT
./scripts/tune_io.sh $CGROUP_PATH $COMPONENT $IO_WEIGHT

# Phase 3: Validation
echo "Phase 3: Validation..."
./scripts/load_test_${COMPONENT}.sh

# Phase 4: Comparison
echo "Phase 4: Comparison..."
./scripts/compare_performance.sh $COMPONENT $ITERATION

echo "=== Calibration Iteration $ITERATION Complete ==="
```

### 6.3 Full Calibration Workflow

```bash
#!/bin/bash
# run_full_calibration.sh - Run full calibration workflow

echo "=== Starting Full Calibration Workflow ==="

# Phase 1: Baseline measurement
echo "Phase 1: Baseline measurement..."
./scripts/measure_baseline.sh
./scripts/aggregate_baseline.sh

# Phase 2: Component calibration
COMPONENTS=("agent-loop" "worker-pool" "wasm-sandbox" "ebpf-agent" "clawfs-daemon" "security-agent" "router" "orchestrator")

for component in "${COMPONENTS[@]}"; do
  echo "=== Calibrating $component ==="

  iteration=0
  converged=0

  while [ $iteration -lt 10 ] && [ $converged -eq 0 ]; do
    ./scripts/run_calibration_iteration.sh $iteration $component

    # Check convergence
    if [ $iteration -gt 2 ]; then
      # Compare last 3 iterations
      ./scripts/check_convergence.sh $component $iteration
      if [ $? -eq 0 ]; then
        converged=1
        echo "[✓] $component converged at iteration $iteration"
      fi
    fi

    iteration=$((iteration + 1))
  done

  if [ $converged -eq 0 ]; then
    echo "[✗] $component failed to converge"
  fi
done

# Phase 3: Final validation
echo "Phase 3: Final validation..."
./scripts/run_all_load_tests.sh

# Phase 4: Report generation
echo "Phase 4: Report generation..."
./scripts/generate_calibration_report.sh

echo "=== Full Calibration Workflow Complete ==="
```

---

## 7. Target Performance Baselines

### 7.1 Baseline Metrics

| Component          | Metric                  | Baseline         | Target (≥80%)     |
| -------------------| ------------------------| -----------------| ------------------|
| **Agent Loop**     | Cold start time         | 2.5s             | ≤3.0s             |
| **Agent Loop**     | Throughput              | 1000 req/s       | ≥800 req/s        |
| **Agent Loop**     | Memory usage            | 512M             | ≤640M             |
| **Agent Loop**     | CPU utilization         | 20%              | ≤25%              |
| **Worker Pool**    | Task completion rate    | 95%              | ≥76%              |
| **Worker Pool**    | Memory per worker       | 64M              | ≤77M              |
| **Worker Pool**    | CPU per worker          | 10%              | ≤12.5%            |
| **WASM Sandbox**   | Tool execution time     | 100ms            | ≤125ms            |
| **WASM Sandbox**   | Memory per instance     | 256M             | ≤307M             |
| **WASM Sandbox**   | CPU per instance        | 5%               | ≤6.25%            |
| **eBPF Agent**     | Event processing rate   | 10000 events/s   | ≥8000 events/s    |
| **eBPF Agent**     | Memory usage            | 256M             | ≤307M             |
| **eBPF Agent**     | CPU utilization         | 10%              | ≤12.5%            |
| **ClawFS Daemon**  | Read throughput         | 100 MB/s         | ≥80 MB/s          |
| **ClawFS Daemon**  | Write throughput        | 50 MB/s          | ≥40 MB/s          |
| **ClawFS Daemon**  | Memory usage            | 512M             | ≤614M             |
| **Security Agent** | Syscall filtering rate  | 50000 syscalls/s | ≥40000 syscalls/s |
| **Security Agent** | Memory usage            | 256M             | ≤307M             |
| **Router**         | Request routing rate    | 5000 req/s       | ≥4000 req/s       |
| **Router**         | Memory usage            | 512M             | ≤614M             |
| **Orchestrator**   | Namespace creation time | 50ms             | ≤62.5ms           |
| **Orchestrator**   | Memory usage            | 512M             | ≤614M             |

### 7.2 Performance Validation

```bash
#!/bin/bash
# validate_performance.sh - Validate performance against baselines

echo "=== Validating Performance Against Baselines ==="

# Read baseline values
baseline_file="/tmp/cgroup-calibration/processed/baseline_summary.txt"

# Validate each component
COMPONENTS=("agent-loop" "worker-pool" "wasm-sandbox" "ebpf-agent" "clawfs-daemon" "security-agent" "router" "orchestrator")

all_passed=1

for component in "${COMPONENTS[@]}"; do
  echo "Validating $component..."

  # Run load test
  ./scripts/load_test_${component}.sh

  # Collect metrics
  metrics_file="/tmp/cgroup-calibration/processed/${component}_metrics.txt"

  # Compare to baseline
  ./scripts/compare_to_baseline.sh $component $baseline_file $metrics_file

  if [ $? -eq 0 ]; then
    echo "[✓] $component meets ≥80% baseline"
  else
    echo "[✗] $component fails ≥80% baseline"
    all_passed=0
  fi
done

if [ $all_passed -eq 1 ]; then
  echo "[✓] All components meet ≥80% baseline"
  exit 0
else
  echo "[✗] Some components fail ≥80% baseline"
  exit 1
fi
```

---

## 8. Expected Outcomes

### 8.1 Calibration Targets

| Metric                  | Target      | Rationale                                              |
| ------------------------| ------------| -------------------------------------------------------|
| Memory reduction        | 10-20%      | Optimize memory allocation based on actual usage       |
| CPU quota reduction     | 5-15%       | Reduce over-provisioning while maintaining performance |
| PIDs limit optimization | 10-30%      | Match actual thread/process counts                     |
| I/O weight tuning       | 5-10%       | Balance I/O priority across components                 |
| Performance retention   | ≥80%        | Maintain acceptable performance levels                 |
| OOM behavior            | Predictable | Ensure graceful degradation under memory pressure      |

### 8.2 Success Criteria

- [ ] All components calibrated through empirical benchmarking
- [ ] Performance ≥80% of IronClaw baseline for all components
- [ ] OOM behavior tested and validated
- [ ] Load testing completed for all scenarios
- [ ] Calibration iteration process documented
- [ ] Optimal resource values documented
- [ ] P1.5 specification updated with calibrated values

### 8.3 Deliverables

1. **Calibration report:** `/tmp/cgroup-calibration/reports/calibration_report.txt`
2. **Optimal values:** `/tmp/cgroup-calibration/processed/optimal_values.json`
3. **Performance comparison:** `/tmp/cgroup-calibration/reports/performance_comparison.txt`
4. **OOM behavior report:** `/tmp/cgroup-calibration/reports/oom_behavior.txt`
5. **Updated P1.5 specification:** `specs/p1/P1.5-cgroup-quotas.calibrated.json`

---

## 9. References

- **P1.5-cgroup-quotas:** Original cgroup quota specification
- **SKILLS.md line 352:** Tokio thread count formula and cgroup v2 pids.max calculation
- **cgroup v2 documentation:** https://docs.kernel.org/admin-guide/cgroup-v2.html
- **systemd.resource-control:** https://www.freedesktop.org/software/systemd/man/systemd.resource-control.html
- **stress-ng documentation:** https://manpages.ubuntu.com/manpages/jammy/man1/stress-ng.1.html

---

## Appendix A: Quick Reference Commands

```bash
# Run full calibration workflow
./scripts/run_full_calibration.sh

# Calibrate specific component
./scripts/run_calibration_iteration.sh 0 agent-loop

# Validate performance
./scripts/validate_performance.sh

# Test OOM behavior
./scripts/test_oom_trigger.sh /sys/fs/cgroup/clawos/wasm.slice wasm-sandbox 256M

# Generate calibration report
./scripts/generate_calibration_report.sh
```

---

## Appendix B: Troubleshooting

### Issue: Component fails to converge
**Symptom:** Calibration iterations do not converge after 10 attempts
**Resolution:**
```bash
# Check for resource contention
./scripts/check_resource_contention.sh

# Increase iteration limit
export MAX_ITERATIONS=20

# Try larger step sizes
export TUNING_STEP_SIZE=0.2
```

### Issue: Performance drops below 80% baseline
**Symptom:** Calibrated values cause performance degradation
**Resolution:**
```bash
# Revert to baseline values
./scripts/revert_to_baseline.sh

# Check for system-wide resource pressure
./scripts/check_system_pressure.sh

# Reduce tuning aggressiveness
export TUNING_STEP_SIZE=0.05
```

### Issue: OOM kills critical components
**Symptom:** Kernel services killed by OOM
**Resolution:**
```bash
# Verify memory.oom.group=0 for kernel services
echo "0" > /sys/fs/cgroup/clawos/kernel.slice/memory.oom.group

# Increase memory limits for kernel services
./scripts/increase_kernel_memory.sh

# Check for memory leaks
./scripts/detect_memory_leaks.sh
```

---

**Document End**
