# P4.3: eBPF Ring Buffer Size Tuning Strategy

**Status:** ðŸ“ DRAFT
**Version:** v1.0
**Date:** 2026-02-24
**Owner:** eBPF Agent
**Related Specs:** P1.3 (eBPF Event Struct Format)

---

## Overview

This specification defines the methodology for tuning eBPF ring buffer sizes to prevent event loss while optimizing memory usage. Ring buffers are the primary communication mechanism between kernel-space eBPF programs and userspace receivers in ClawOS.

**Critical Goal:** Zero event loss under normal operating conditions with minimal memory overhead.

---

## Design Principles

1. **Zero Loss Priority:** Event loss is unacceptable for security monitoring
2. **Adaptive Sizing:** Buffer sizes must adapt to workload characteristics
3. **Memory Efficiency:** Avoid over-provisioning while maintaining safety margins
4. **Monitoring-Driven:** Continuous monitoring informs sizing decisions
5. **Event-Type Awareness:** Different event types require different strategies

---

## Event Type Reference (from P1.3)

| Event Type | Struct Size | Typical Rate | Recommended Buffer |
|------------|-------------|--------------|-------------------|
| AnomalyEvent | 1056 bytes | 100/sec | 64 KB |
| SyscallTraceEvent | 104 bytes | 10,000/sec | 2 MB |
| FileAccessEvent | 304 bytes | 5,000/sec | 1 MB |
| NetworkEvent | 72 bytes | 20,000/sec | 4 MB |
| CgroupEvent | 304 bytes | 500/sec | 128 KB |

---

## 1. Ring Buffer Sizing Methodology

### 1.1 Core Sizing Formula

```
BUFFER_SIZE = (EVENT_SIZE Ã— EVENTS_PER_SEC Ã— BUFFER_TIME) Ã— SAFETY_FACTOR
```

**Parameters:**
- `EVENT_SIZE`: Size of event struct (from P1.3)
- `EVENTS_PER_SEC`: Expected event rate (measured or estimated)
- `BUFFER_TIME`: Time window to buffer (typically 1-5 seconds)
- `SAFETY_FACTOR`: Multiplier for burst handling (typically 2-4x)

### 1.2 Buffer Time Selection

| Scenario | Buffer Time | Rationale |
|----------|-------------|-----------|
| Low-latency monitoring | 1 second | Minimize detection delay |
| Standard monitoring | 2-3 seconds | Balance latency and burst handling |
| High-burst environments | 5 seconds | Handle traffic spikes |
| Forensic analysis | 10 seconds | Capture complete attack sequences |

### 1.3 Safety Factor Guidelines

| Burst Pattern | Safety Factor | Use Case |
|---------------|---------------|----------|
| Predictable workload | 2x | Stable production systems |
| Moderate variability | 3x | Web servers, databases |
| High variability | 4x | CI/CD, development environments |
| Attack scenarios | 5x | Security monitoring during incidents |

### 1.4 Calculation Examples

**Example 1: SyscallTraceEvent (High Volume)**
```
EVENT_SIZE = 104 bytes
EVENTS_PER_SEC = 10,000
BUFFER_TIME = 2 seconds
SAFETY_FACTOR = 3

BUFFER_SIZE = 104 Ã— 10,000 Ã— 2 Ã— 3
           = 6,240,000 bytes
           â‰ˆ 6 MB (rounded to power of 2)
```

**Example 2: AnomalyEvent (Low Volume)**
```
EVENT_SIZE = 1056 bytes
EVENTS_PER_SEC = 100
BUFFER_TIME = 3 seconds
SAFETY_FACTOR = 2

BUFFER_SIZE = 1056 Ã— 100 Ã— 3 Ã— 2
           = 633,600 bytes
           â‰ˆ 1 MB (rounded to power of 2)
```

**Example 3: NetworkEvent (Very High Volume)**
```
EVENT_SIZE = 72 bytes
EVENTS_PER_SEC = 20,000
BUFFER_TIME = 1 second
SAFETY_FACTOR = 4

BUFFER_SIZE = 72 Ã— 20,000 Ã— 1 Ã— 4
           = 5,760,000 bytes
           â‰ˆ 8 MB (rounded to power of 2)
```

### 1.5 Power-of-2 Alignment

**Rule:** Always round buffer sizes to the nearest power of 2.

**Rationale:**
- eBPF ring buffers perform better with power-of-2 sizes
- Simplifies modulo arithmetic in kernel
- Reduces memory fragmentation

**Rounding Table:**

| Calculated Size | Rounded Size | Notes |
|-----------------|--------------|-------|
| 500 KB - 1 MB | 1 MB | Minimum practical size |
| 1 MB - 2 MB | 2 MB | Standard size |
| 2 MB - 4 MB | 4 MB | High-volume events |
| 4 MB - 8 MB | 8 MB | Very high-volume events |
| 8 MB - 16 MB | 16 MB | Extreme scenarios |

---

## 2. Event Loss Detection Procedures

### 2.1 Kernel-Space Detection

**Method 1: Ring Buffer Full Check**

```c
// In eBPF program
int event_sent = bpf_ringbuf_output(&ringbuf, &event, sizeof(event), 0);
if (event_sent != 0) {
    // Event dropped - buffer full
    __sync_fetch_and_add(&dropped_count, 1);
}
```

**Method 2: Reserve-Commit Pattern**

```c
// Reserve space first
void *reserved = bpf_ringbuf_reserve(&ringbuf, sizeof(event), 0);
if (!reserved) {
    // Buffer full - cannot reserve
    __sync_fetch_and_add(&dropped_count, 1);
    return;
}

// Copy event data
__builtin_memcpy(reserved, &event, sizeof(event));

// Commit event
bpf_ringbuf_submit(reserved, 0);
```

### 2.2 Userspace Detection

**Method 1: Poll Timeout Detection**

```rust
// In userspace receiver
use aya::Ebpf;

fn check_for_loss(ebpf: &Ebpf) -> Result<(), Error> {
    let timeout = Duration::from_millis(100);

    // If poll times out but kernel reports events, there's loss
    match ebpf.poll(timeout) {
        Ok(events) => {
            if events.is_empty() && has_pending_kernel_events() {
                log_event_loss();
            }
        }
        Err(_) => {
            // Poll error - potential loss
            log_event_loss();
        }
    }

    Ok(())
}
```

**Method 2: Sequence Number Tracking**

```rust
// Add sequence number to each event
#[repr(C, packed)]
struct EventHeader {
    pub version: u8,
    pub event_id: u8,
    pub sequence: u64,  // Monotonically increasing
    pub timestamp_ns: u64,
}

// In userspace receiver
fn detect_sequence_gaps(last_seq: u64, current_seq: u64) {
    if current_seq > last_seq + 1 {
        let lost = current_seq - last_seq - 1;
        log::warn!("Detected {} lost events", lost);
    }
}
```

**Method 3: bpftool Statistics**

```bash
# Check for dropped events
bpftool prog show

# Look for:
# - run_time_ns
# - run_cnt
# - missed events (if available)
```

### 2.3 Loss Metrics Collection

**Required Metrics:**

| Metric | Type | Description |
|--------|------|-------------|
| `dropped_events_total` | Counter | Total events dropped |
| `dropped_events_per_sec` | Gauge | Current drop rate |
| `buffer_full_count` | Counter | Times buffer was full |
| `buffer_utilization` | Gauge | Current buffer usage % |
| `loss_rate` | Gauge | Dropped / (Dropped + Received) |

**Prometheus Export Format:**

```rust
// Metrics definition
lazy_static! {
    static ref DROPPED_EVENTS_TOTAL: IntCounter = register_int_counter!(
        "ebpf_dropped_events_total",
        "Total number of eBPF events dropped"
    ).unwrap();

    static ref BUFFER_UTILIZATION: Gauge = register_gauge!(
        "ebpf_buffer_utilization_percent",
        "Current ring buffer utilization percentage"
    ).unwrap();

    static ref LOSS_RATE: Gauge = register_gauge!(
        "ebpf_loss_rate",
        "Event loss rate (dropped / total)"
    ).unwrap();
}
```

### 2.4 Loss Alerting

**Alert Thresholds:**

| Metric | Warning | Critical | Action |
|--------|---------|----------|--------|
| Loss Rate | > 0.1% | > 1% | Increase buffer size |
| Buffer Full Count | > 10/min | > 100/min | Immediate investigation |
| Dropped Events/sec | > 10 | > 100 | Scale up receiver |

**Alert Example (Prometheus):**

```yaml
groups:
  - name: ebpf_ring_buffer
    rules:
      - alert: HighEventLossRate
        expr: rate(ebpf_dropped_events_total[5m]) > 0.01
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High eBPF event loss rate detected"
          description: "Event loss rate is {{ $value }} events/sec"

      - alert: CriticalEventLoss
        expr: rate(ebpf_dropped_events_total[1m]) > 100
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "Critical eBPF event loss detected"
          description: "Losing {{ $value }} events/sec - immediate action required"
```

---

## 3. Adaptive Sizing Algorithms

### 3.1 Static Sizing (Baseline)

**Use Case:** Stable, predictable workloads

**Algorithm:**
```
1. Measure event rate for 24 hours
2. Calculate 99th percentile rate
3. Apply sizing formula with safety factor = 2
4. Set buffer size permanently
```

**Pros:**
- Simple to implement
- Predictable memory usage
- No runtime overhead

**Cons:**
- Cannot handle unexpected bursts
- May over-provision for normal operation

### 3.2 Dynamic Sizing (Recommended)

**Use Case:** Variable workloads, production systems

**Algorithm:**

```rust
struct AdaptiveBuffer {
    current_size: usize,
    min_size: usize,
    max_size: usize,
    target_utilization: f64,  // e.g., 0.7 (70%)
    adjustment_factor: f64,    // e.g., 1.5 (50% increase)
    cooldown_period: Duration,
    last_adjustment: Instant,
}

impl AdaptiveBuffer {
    fn adjust_size(&mut self, utilization: f64) -> Result<(), Error> {
        // Check cooldown
        if self.last_adjustment.elapsed() < self.cooldown_period {
            return Ok(());
        }

        let new_size = if utilization > 0.9 {
            // Buffer nearly full - increase size
            let proposed = (self.current_size as f64 * self.adjustment_factor) as usize;
            proposed.min(self.max_size)
        } else if utilization < 0.3 && self.current_size > self.min_size {
            // Buffer underutilized - decrease size
            let proposed = (self.current_size as f64 / self.adjustment_factor) as usize;
            proposed.max(self.min_size)
        } else {
            // Within target range - no change
            return Ok(());
        };

        // Apply new size
        self.resize_buffer(new_size)?;
        self.current_size = new_size;
        self.last_adjustment = Instant::now();

        log::info!("Adjusted buffer size to {} bytes (utilization: {:.1}%)",
                   new_size, utilization * 100.0);

        Ok(())
    }

    fn resize_buffer(&self, new_size: usize) -> Result<(), Error> {
        // Implementation depends on eBPF framework
        // May require reloading eBPF program or using map resize API
        todo!("Implement buffer resize")
    }
}
```

**Configuration Parameters:**

| Parameter | Default | Range | Description |
|-----------|---------|-------|-------------|
| `min_size` | 64 KB | 64 KB - 1 MB | Minimum buffer size |
| `max_size` | 16 MB | 1 MB - 64 MB | Maximum buffer size |
| `target_utilization` | 0.7 | 0.5 - 0.8 | Target utilization % |
| `adjustment_factor` | 1.5 | 1.2 - 2.0 | Size change multiplier |
| `cooldown_period` | 60 sec | 30 - 300 sec | Minimum time between adjustments |

### 3.3 Predictive Sizing (Advanced)

**Use Case:** Systems with predictable patterns (e.g., daily traffic spikes)

**Algorithm:**

```rust
struct PredictiveBuffer {
    historical_rates: VecDeque<f64>,
    prediction_window: usize,  // Number of samples to use
    forecast_horizon: Duration,  // How far to predict
}

impl PredictiveBuffer {
    fn predict_rate(&self) -> f64 {
        // Use simple moving average
        let sum: f64 = self.historical_rates.iter().sum();
        sum / self.historical_rates.len() as f64
    }

    fn calculate_buffer_size(&self, predicted_rate: f64) -> usize {
        let event_size = self.get_event_size();
        let buffer_time = Duration::from_secs(5);
        let safety_factor = 3.0;

        let size = event_size as f64 * predicted_rate
                 * buffer_time.as_secs_f64()
                 * safety_factor;

        round_to_power_of_two(size as usize)
    }

    fn update_prediction(&mut self, current_rate: f64) {
        self.historical_rates.push_back(current_rate);
        if self.historical_rates.len() > self.prediction_window {
            self.historical_rates.pop_front();
        }
    }
}
```

**Prediction Models:**

| Model | Complexity | Accuracy | Use Case |
|-------|------------|----------|----------|
| Moving Average | Low | Medium | Simple patterns |
| Exponential Smoothing | Low | Medium | Trending data |
| Linear Regression | Medium | High | Linear trends |
| ARIMA | High | Very High | Complex patterns |
| LSTM (ML) | Very High | Very High | Highly variable data |

### 3.4 Hybrid Sizing (Production-Ready)

**Combines:** Dynamic + Predictive

```rust
struct HybridBuffer {
    dynamic: AdaptiveBuffer,
    predictive: PredictiveBuffer,
    dynamic_weight: f64,  // 0.0 - 1.0
    predictive_weight: f64,  // 0.0 - 1.0
}

impl HybridBuffer {
    fn calculate_optimal_size(&self) -> usize {
        let dynamic_size = self.dynamic.current_size;
        let predictive_size = self.predictive.calculate_buffer_size(
            self.predictive.predict_rate()
        );

        // Weighted average
        let weighted = (dynamic_size as f64 * self.dynamic_weight)
                     + (predictive_size as f64 * self.predictive_weight);

        round_to_power_of_two(weighted as usize)
    }
}
```

---

## 4. Performance vs Memory Trade-off Analysis

### 4.1 Memory Cost Analysis

**Per-Event-Type Memory Requirements:**

| Event Type | Size | 1K Events | 10K Events | 100K Events |
|------------|------|-----------|------------|-------------|
| AnomalyEvent | 1056 B | 1 MB | 10 MB | 100 MB |
| SyscallTraceEvent | 104 B | 100 KB | 1 MB | 10 MB |
| FileAccessEvent | 304 B | 300 KB | 3 MB | 30 MB |
| NetworkEvent | 72 B | 70 KB | 700 KB | 7 MB |
| CgroupEvent | 304 B | 300 KB | 3 MB | 30 MB |

**Total Memory for All Event Types (Recommended Sizes):**

```
AnomalyEvent:    64 KB
SyscallTraceEvent: 2 MB
FileAccessEvent: 1 MB
NetworkEvent: 4 MB
CgroupEvent: 128 KB
--------------------------------
Total: 7.2 MB
```

### 4.2 Performance Impact

**Buffer Size vs Throughput:**

| Buffer Size | Max Throughput | Latency | CPU Overhead |
|-------------|----------------|---------|--------------|
| 64 KB | 1K events/sec | < 1ms | Low |
| 256 KB | 5K events/sec | < 1ms | Low |
| 1 MB | 20K events/sec | 1-2ms | Medium |
| 4 MB | 100K events/sec | 2-5ms | Medium |
| 16 MB | 500K events/sec | 5-10ms | High |

**Key Findings:**
- Small buffers (< 256 KB) limit throughput due to frequent full conditions
- Large buffers (> 16 MB) increase latency and CPU overhead
- Sweet spot: 1-4 MB for most production workloads

### 4.3 Trade-off Decision Matrix

| Scenario | Priority | Buffer Strategy | Rationale |
|----------|----------|-----------------|-----------|
| Security monitoring | Zero loss | Large buffer (4-8x) | Security > memory |
| Performance monitoring | Low overhead | Medium buffer (2-3x) | Balance |
| Development | Flexibility | Dynamic sizing | Adapt to changes |
| Production | Stability | Hybrid sizing | Predictable + adaptive |
| Resource-constrained | Memory efficiency | Small buffer (1.5-2x) | Memory > loss tolerance |

### 4.4 Cost-Benefit Analysis

**Formula:**
```
BENEFIT = (EVENTS_SAVED Ã— EVENT_VALUE) - (MEMORY_COST Ã— MEMORY_PRICE)
```

**Example Calculation:**

```
Scenario: Security monitoring
- Current buffer: 2 MB
- Proposed buffer: 8 MB
- Events saved per day: 1,000
- Event value (security incident): $10,000
- Memory cost: 6 MB
- Memory price: $0.01/GB/day

BENEFIT = (1,000 Ã— $10,000) - (0.006 GB Ã— $0.01)
        = $10,000,000 - $0.00006
        = $9,999,999.94

Conclusion: Worthwhile investment
```

---

## 5. Monitoring for Buffer Overflow

### 5.1 Real-Time Metrics

**Required Metrics:**

```rust
pub struct BufferMetrics {
    // Capacity metrics
    pub buffer_size: usize,
    pub buffer_used: usize,
    pub buffer_available: usize,
    pub utilization_percent: f64,

    // Event metrics
    pub events_received: u64,
    pub events_processed: u64,
    pub events_dropped: u64,
    pub events_per_sec: f64,

    // Loss metrics
    pub loss_rate: f64,
    pub consecutive_drops: u32,
    pub last_drop_time: Option<Instant>,

    // Performance metrics
    pub avg_read_latency: Duration,
    pub p99_read_latency: Duration,
    pub avg_write_latency: Duration,
}
```

### 5.2 Monitoring Implementation

**Prometheus Metrics:**

```rust
use prometheus::{IntCounter, Gauge, Histogram};

lazy_static! {
    // Buffer capacity
    static ref BUFFER_SIZE: Gauge = register_gauge!(
        "ebpf_ring_buffer_size_bytes",
        "Ring buffer size in bytes"
    ).unwrap();

    static ref BUFFER_USED: Gauge = register_gauge!(
        "ebpf_ring_buffer_used_bytes",
        "Ring buffer used bytes"
    ).unwrap();

    static ref BUFFER_UTILIZATION: Gauge = register_gauge!(
        "ebpf_ring_buffer_utilization_percent",
        "Ring buffer utilization percentage"
    ).unwrap();

    // Event counts
    static ref EVENTS_RECEIVED: IntCounter = register_int_counter!(
        "ebpf_events_received_total",
        "Total events received from kernel"
    ).unwrap();

    static ref EVENTS_PROCESSED: IntCounter = register_int_counter!(
        "ebpf_events_processed_total",
        "Total events processed by userspace"
    ).unwrap();

    static ref EVENTS_DROPPED: IntCounter = register_int_counter!(
        "ebpf_events_dropped_total",
        "Total events dropped due to buffer overflow"
    ).unwrap();

    // Performance
    static ref READ_LATENCY: Histogram = register_histogram!(
        "ebpf_read_latency_seconds",
        "Event read latency in seconds"
    ).unwrap();
}
```

### 5.3 Dashboard Configuration (Grafana)

**Panel 1: Buffer Utilization**

```json
{
  "title": "Ring Buffer Utilization",
  "targets": [
    {
      "expr": "ebpf_ring_buffer_utilization_percent",
      "legendFormat": "{{event_type}}"
    }
  ],
  "alert": {
    "conditions": [
      {
        "evaluator": {
          "params": [90],
          "type": "gt"
        },
        "operator": {
          "type": "and"
        }
      }
    ]
  }
}
```

**Panel 2: Event Loss Rate**

```json
{
  "title": "Event Loss Rate",
  "targets": [
    {
      "expr": "rate(ebpf_events_dropped_total[5m])",
      "legendFormat": "Drops/sec"
    }
  ]
}
```

**Panel 3: Events Throughput**

```json
{
  "title": "Events Throughput",
  "targets": [
    {
      "expr": "rate(ebpf_events_received_total[1m])",
      "legendFormat": "Received/sec"
    },
    {
      "expr": "rate(ebpf_events_processed_total[1m])",
      "legendFormat": "Processed/sec"
    }
  ]
}
```

### 5.4 Log Analysis

**Structured Logging Format:**

```rust
use serde::Serialize;

#[derive(Serialize)]
struct BufferEventLog {
    timestamp: i64,
    event_type: String,
    buffer_size: usize,
    buffer_used: usize,
    utilization: f64,
    dropped: bool,
    action: Option<String>,  // e.g., "buffer_resized"
}

fn log_buffer_event(event: BufferEventLog) {
    log::info!(
        "{}",
        serde_json::to_string(&event).unwrap()
    );
}
```

**Log Query Examples:**

```bash
# Find buffer overflow events
grep "dropped:true" /var/log/clawos/ebpf.log

# Find buffer resize actions
grep "action:buffer_resized" /var/log/clawos/ebpf.log

# Analyze utilization patterns
jq -r '.utilization' /var/log/clawos/ebpf.log | \
  awk '{sum+=$1; count++} END {print "Avg:", sum/count}'
```

---

## 6. Size Optimization Per Event Type

### 6.1 AnomalyEvent (1056 bytes)

**Characteristics:**
- Low volume (100/sec)
- High value (security critical)
- Burst-prone (attack scenarios)

**Sizing Strategy:**

| Scenario | Rate | Buffer Time | Safety Factor | Buffer Size |
|----------|------|-------------|---------------|-------------|
| Normal | 100/sec | 3 sec | 2x | 640 KB â†’ 1 MB |
| Attack | 1,000/sec | 5 sec | 4x | 21 MB â†’ 32 MB |
| Forensic | 100/sec | 10 sec | 2x | 2 MB â†’ 2 MB |

**Optimization Tips:**
- Use larger safety factor during security incidents
- Implement event prioritization (drop low-severity first)
- Consider separate buffer for critical events

### 6.2 SyscallTraceEvent (104 bytes)

**Characteristics:**
- High volume (10,000/sec)
- Medium value (performance monitoring)
- Predictable patterns

**Sizing Strategy:**

| Scenario | Rate | Buffer Time | Safety Factor | Buffer Size |
|----------|------|-------------|---------------|-------------|
| Idle | 1,000/sec | 2 sec | 2x | 416 KB â†’ 512 KB |
| Normal | 10,000/sec | 2 sec | 3x | 6.2 MB â†’ 8 MB |
| Peak | 50,000/sec | 1 sec | 4x | 20.8 MB â†’ 32 MB |

**Optimization Tips:**
- Implement sampling during peak loads
- Use event filtering to reduce volume
- Consider per-CPU buffers for scalability

### 6.3 FileAccessEvent (304 bytes)

**Characteristics:**
- Medium volume (5,000/sec)
- High value (security monitoring)
- Burst-prone (file scans)

**Sizing Strategy:**

| Scenario | Rate | Buffer Time | Safety Factor | Buffer Size |
|----------|------|-------------|---------------|-------------|
| Normal | 5,000/sec | 2 sec | 2x | 6 MB â†’ 8 MB |
| Scan | 50,000/sec | 3 sec | 3x | 136 MB â†’ 256 MB |
| Backup | 20,000/sec | 2 sec | 2x | 24 MB â†’ 32 MB |

**Optimization Tips:**
- Detect and handle bulk operations (scans, backups)
- Implement path-based filtering
- Use separate buffers for different directories

### 6.4 NetworkEvent (72 bytes)

**Characteristics:**
- Very high volume (20,000/sec)
- Medium value (network monitoring)
- Highly variable

**Sizing Strategy:**

| Scenario | Rate | Buffer Time | Safety Factor | Buffer Size |
|----------|------|-------------|---------------|-------------|
| Idle | 1,000/sec | 1 sec | 2x | 144 KB â†’ 256 KB |
| Normal | 20,000/sec | 1 sec | 3x | 4.3 MB â†’ 8 MB |
| DDoS | 1,000,000/sec | 0.5 sec | 5x | 180 MB â†’ 256 MB |

**Optimization Tips:**
- Implement aggressive sampling during attacks
- Use connection tracking to reduce duplicates
- Consider per-interface buffers

### 6.5 CgroupEvent (304 bytes)

**Characteristics:**
- Low volume (500/sec)
- Medium value (resource monitoring)
- Predictable patterns

**Sizing Strategy:**

| Scenario | Rate | Buffer Time | Safety Factor | Buffer Size |
|----------|------|-------------|---------------|-------------|
| Normal | 500/sec | 3 sec | 2x | 912 KB â†’ 1 MB |
| Scaling | 5,000/sec | 2 sec | 3x | 9.1 MB â†’ 16 MB |
| Stress | 10,000/sec | 1 sec | 4x | 12 MB â†’ 16 MB |

**Optimization Tips:**
- Implement threshold-based filtering
- Use separate buffers per cgroup
- Aggregate metrics before sending

---

## 7. Implementation Guidelines

### 7.1 Buffer Creation (Aya-rs)

```rust
use aya::{Ebpf, programs::KProbe};

fn create_ring_buffer(
    ebpf: &mut Ebpf,
    name: &str,
    size: usize,
) -> Result<(), Error> {
    // Create ring buffer map
    let map = ebpf.map_mut(name).ok_or(Error::MapNotFound)?;

    // Resize if needed
    if let Err(e) = map.resize(size, 0) {
        log::error!("Failed to resize ring buffer {}: {}", name, e);
        return Err(e.into());
    }

    log::info!("Created ring buffer {} with size {} bytes", name, size);
    Ok(())
}
```

### 7.2 Event Submission (Kernel Space)

```c
// In eBPF program
struct {
    __uint(type, BPF_MAP_TYPE_RINGBUF);
    __uint(max_entries, 8388608);  // 8 MB
} ringbuf SEC(".maps");

SEC("kprobe/sys_execve")
int handle_execve(struct pt_regs *ctx)
{
    struct event_t *e;

    // Reserve space
    e = bpf_ringbuf_reserve(&ringbuf, sizeof(*e), 0);
    if (!e) {
        // Buffer full - increment counter
        __sync_fetch_and_add(&dropped_events, 1);
        return 0;
    }

    // Fill event
    e->timestamp = bpf_ktime_get_ns();
    e->pid = bpf_get_current_pid_tgid() >> 32;
    // ... fill other fields

    // Submit event
    bpf_ringbuf_submit(e, 0);

    return 0;
}
```

### 7.3 Event Consumption (Userspace)

```rust
use aya::{Ebpf, maps::RingBuffer};
use tokio::signal;

async fn consume_events(ebpf: &Ebpf) -> Result<(), Error> {
    let mut ringbuf = RingBuffer::try_from(ebpf.map_mut("ringbuf")?)?;

    loop {
        // Poll for events with timeout
        match ringbuf.poll(Duration::from_millis(100)) {
            Ok(Some(data)) => {
                // Process event
                process_event(data)?;
            }
            Ok(None) => {
                // No events available
                continue;
            }
            Err(e) => {
                log::error!("Ring buffer error: {}", e);
                return Err(e.into());
            }
        }
    }
}
```

### 7.4 Adaptive Sizing Implementation

```rust
struct BufferManager {
    ebpf: Ebpf,
    buffers: HashMap<String, AdaptiveBuffer>,
    metrics: BufferMetrics,
}

impl BufferManager {
    async fn run(&mut self) -> Result<(), Error> {
        let mut interval = tokio::time::interval(Duration::from_secs(10));

        loop {
            interval.tick().await;

            // Update metrics
            self.update_metrics().await?;

            // Check each buffer
            for (name, buffer) in self.buffers.iter_mut() {
                let utilization = self.get_buffer_utilization(name)?;
                buffer.adjust_size(utilization)?;
            }
        }
    }

    fn get_buffer_utilization(&self, name: &str) -> Result<f64, Error> {
        let map = self.ebpf.map(name).ok_or(Error::MapNotFound)?;
        let info = map.info()?;

        let used = info.value_size() * info.key_count();
        let total = info.max_entries();

        Ok(used as f64 / total as f64)
    }
}
```

---

## 8. Testing and Validation

### 8.1 Unit Tests

```rust
#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_buffer_size_calculation() {
        let size = calculate_buffer_size(
            104,      // event size
            10000,    // events per sec
            2,        // buffer time (sec)
            3.0,      // safety factor
        );

        assert_eq!(size, 8 * 1024 * 1024);  // 8 MB
    }

    #[test]
    fn test_power_of_two_rounding() {
        assert_eq!(round_to_power_of_two(500_000), 524_288);  // 512 KB
        assert_eq!(round_to_power_of_two(3_000_000), 4_194_304);  // 4 MB
        assert_eq!(round_to_power_of_two(10_000_000), 16_777_216);  // 16 MB
    }

    #[test]
    fn test_adaptive_buffer_adjustment() {
        let mut buffer = AdaptiveBuffer::new(1024 * 1024, 64 * 1024, 16 * 1024 * 1024);

        // High utilization - should increase
        buffer.adjust_size(0.95).unwrap();
        assert!(buffer.current_size > 1024 * 1024);

        // Low utilization - should decrease
        buffer.adjust_size(0.2).unwrap();
        assert!(buffer.current_size < buffer.current_size);
    }
}
```

### 8.2 Load Testing

**Test Scenarios:**

```bash
# Test 1: Sustained high load
./load_test --events 1000000 --rate 10000 --duration 60

# Test 2: Burst load
./load_test --events 100000 --rate 50000 --burst 5

# Test 3: Memory pressure
./load_test --events 1000000 --rate 5000 --memory-limit 100MB

# Test 4: Event loss detection
./load_test --events 1000000 --rate 20000 --buffer-size 1MB
```

**Success Criteria:**

| Test | Loss Rate | Latency | CPU Usage |
|------|-----------|---------|-----------|
| Sustained load | < 0.01% | < 10ms | < 50% |
| Burst load | < 0.1% | < 50ms | < 80% |
| Memory pressure | < 1% | < 100ms | < 90% |
| Loss detection | 100% | N/A | N/A |

### 8.3 Chaos Testing

**Failure Scenarios:**

1. **Receiver Crash:**
   - Stop userspace receiver
   - Continue generating events
   - Verify buffer fills and drops are detected
   - Restart receiver and verify recovery

2. **Memory Exhaustion:**
   - Reduce available memory
   - Verify graceful degradation
   - Check for OOM kills

3. **CPU Saturation:**
   - Run CPU-intensive tasks
   - Verify event processing continues
   - Check for increased latency

4. **Network Partition:**
   - Block network to remote collectors
   - Verify local buffering
   - Check for backlog handling

---

## 9. Troubleshooting Guide

### 9.1 Common Issues

**Issue 1: High Event Loss Rate**

**Symptoms:**
- `ebpf_events_dropped_total` increasing rapidly
- `ebpf_ring_buffer_utilization_percent` > 90%
- Alerts firing

**Diagnosis:**
```bash
# Check buffer utilization
bpftool map show name ringbuf

# Check event rates
grep "events_received" /var/log/clawos/ebpf.log | \
  tail -100 | awk '{print $NF}' | \
  awk '{sum+=$1; count++} END {print "Avg:", sum/count}'
```

**Solutions:**
1. Increase buffer size (2x)
2. Reduce event rate (filtering, sampling)
3. Scale up receiver (more CPU, faster processing)
4. Implement event prioritization

**Issue 2: Memory Exhaustion**

**Symptoms:**
- OOM kills
- System sluggishness
- High memory usage

**Diagnosis:**
```bash
# Check memory usage
free -h

# Check buffer sizes
bpftool map show | grep ringbuf
```

**Solutions:**
1. Reduce buffer sizes
2. Implement dynamic sizing
3. Add memory limits
4. Use per-CPU buffers

**Issue 3: High Latency**

**Symptoms:**
- Events delayed by > 1 second
- `ebpf_read_latency_seconds` high
- Stale monitoring data

**Diagnosis:**
```bash
# Check read latency
grep "read_latency" /var/log/clawos/ebpf.log | \
  tail -100 | awk '{print $NF}' | \
  awk '{sum+=$1; count++} END {print "Avg:", sum/count}'
```

**Solutions:**
1. Reduce buffer size
2. Increase receiver processing speed
3. Implement batching
4. Use multiple receivers

### 9.2 Debug Commands

```bash
# View all ring buffers
bpftool map show | grep ringbuf

# View buffer statistics
bpftool map dump name ringbuf

# View program statistics
bpftool prog show

# Trace eBPF program execution
bpftrace -e 'kprobe:bpf_ringbuf_output { printf("ringbuf output\n"); }'

# Monitor event loss
watch -n 1 'bpftool prog show | grep missed'
```

---

## 10. Best Practices

### 10.1 Design Principles

1. **Start Conservative:** Begin with 2x safety factor, adjust based on metrics
2. **Monitor Continuously:** Never set and forget - always monitor
3. **Test Thoroughly:** Validate sizing decisions with load tests
4. **Document Decisions:** Keep records of sizing rationale
5. **Plan for Growth:** Design for 10x future growth

### 10.2 Operational Guidelines

1. **Alert Early:** Set alerts at 70% utilization, not 90%
2. **Automate Responses:** Auto-scale buffers when possible
3. **Review Regularly:** Re-evaluate sizing monthly
4. **Share Knowledge:** Document lessons learned
5. **Prepare for Incidents:** Have runbooks for buffer overflow

### 10.3 Security Considerations

1. **Protect Critical Events:** Prioritize security events over others
2. **Detect Tampering:** Monitor for unexpected buffer changes
3. **Audit Access:** Log all buffer resize operations
4. **Secure Metrics:** Protect monitoring endpoints
5. **Validate Data:** Verify event integrity

---

## 11. References

- **P1.3:** eBPF Event Struct Format Specification
- **Aya-rs Documentation:** https://aya-rs.dev/
- **Linux Kernel eBPF Documentation:** https://www.kernel.org/doc/html/latest/bpf/index.html
- **BPF Performance Tools:** https://www.brendangregg.com/bpf-performance-tools-book.html
- **Prometheus Best Practices:** https://prometheus.io/docs/practices/naming/

---

## Appendix A: Configuration Examples

### A.1 Production Configuration

```toml
[ring_buffer]
# AnomalyEvent
anomaly_size = 1048576  # 1 MB
anomaly_min = 65536     # 64 KB
anomaly_max = 33554432  # 32 MB

# SyscallTraceEvent
syscall_size = 8388608  # 8 MB
syscall_min = 524288    # 512 KB
syscall_max = 67108864  # 64 MB

# FileAccessEvent
file_access_size = 8388608  # 8 MB
file_access_min = 1048576   # 1 MB
file_access_max = 268435456 # 256 MB

# NetworkEvent
network_size = 8388608  # 8 MB
network_min = 262144    # 256 KB
network_max = 268435456 # 256 MB

# CgroupEvent
cgroup_size = 1048576  # 1 MB
cgroup_min = 65536     # 64 KB
cgroup_max = 16777216  # 16 MB

[adaptive]
enabled = true
target_utilization = 0.7
adjustment_factor = 1.5
cooldown_period = 60

[monitoring]
metrics_enabled = true
alert_utilization_threshold = 0.7
alert_loss_rate_threshold = 0.001
```

### A.2 Development Configuration

```toml
[ring_buffer]
# Smaller buffers for development
anomaly_size = 262144    # 256 KB
syscall_size = 2097152   # 2 MB
file_access_size = 2097152  # 2 MB
network_size = 2097152   # 2 MB
cgroup_size = 262144     # 256 KB

[adaptive]
enabled = true
target_utilization = 0.5
adjustment_factor = 2.0
cooldown_period = 30

[monitoring]
metrics_enabled = true
alert_utilization_threshold = 0.8
alert_loss_rate_threshold = 0.01
```

---

## Appendix B: Quick Reference

### B.1 Sizing Formula

```
BUFFER_SIZE = round_to_power_of_2(
    EVENT_SIZE Ã— EVENTS_PER_SEC Ã— BUFFER_TIME Ã— SAFETY_FACTOR
)
```

### B.2 Default Sizes

| Event Type | Default Size | Min | Max |
|------------|--------------|-----|-----|
| AnomalyEvent | 1 MB | 64 KB | 32 MB |
| SyscallTraceEvent | 8 MB | 512 KB | 64 MB |
| FileAccessEvent | 8 MB | 1 MB | 256 MB |
| NetworkEvent | 8 MB | 256 KB | 256 MB |
| CgroupEvent | 1 MB | 64 KB | 16 MB |

### B.3 Alert Thresholds

| Metric | Warning | Critical |
|--------|---------|----------|
| Utilization | > 70% | > 90% |
| Loss Rate | > 0.1% | > 1% |
| Drops/sec | > 10 | > 100 |

---

**END OF SPECIFICATION**
