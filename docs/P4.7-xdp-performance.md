# P4.7: XDP Filter Performance Test Specification

## Overview

This document defines performance testing requirements and procedures for the XDP (eXpress Data Path) network filter implementation, specifically targeting PostgreSQL traffic filtering on TCP port 5432.

**Task Reference:** B-04 - XDP network filter (TCP:5432 PostgreSQL only)

---

## 1. Performance Baseline Requirements

### 1.1 Packet Processing Throughput

| Metric | Minimum Requirement | Target | Measurement Unit |
|--------|---------------------|--------|------------------|
| **Baseline (no filter)** | 10 Mpps | 15 Mpps | packets/second |
| **XDP_DROP (all traffic)** | 8 Mpps | 12 Mpps | packets/second |
| **XDP_PASS (allow all)** | 9 Mpps | 14 Mpps | packets/second |
| **XDP_TX (redirect)** | 7 Mpps | 10 Mpps | packets/second |
| **PostgreSQL filter (TCP:5432)** | 6 Mpps | 9 Mpps | packets/second |

**Notes:**
- Mpps = million packets per second
- Baseline measured on 10 Gbps NIC with 64-byte packets
- Requirements assume single-core XDP program execution
- Multi-core scaling should achieve near-linear improvement

### 1.2 CPU Utilization

| Scenario | Max CPU Usage | Target CPU Usage |
|----------|---------------|------------------|
| Idle (no traffic) | < 1% | < 0.5% |
| 1 Mpps traffic | < 15% | < 10% |
| 5 Mpps traffic | < 50% | < 35% |
| 10 Mpps traffic | < 90% | < 70% |

### 1.3 Memory Footprint

| Metric | Maximum | Target |
|--------|---------|--------|
| XDP program size | 4 KB | 2 KB |
| Per-packet map overhead | 64 bytes | 32 bytes |
| Connection tracking entries | 10,000 | 5,000 |

---

## 2. TCP:5432 PostgreSQL Filtering Validation

### 2.1 Filter Logic

The XDP filter must implement the following logic:

```c
// Pseudo-code for XDP filter logic
SEC("xdp")
int postgres_filter(struct xdp_md *ctx) {
    void *data_end = (void *)(long)ctx->data_end;
    void *data = (void *)(long)ctx->data;

    // Parse Ethernet header
    struct ethhdr *eth = data;
    if ((void *)(eth + 1) > data_end)
        return XDP_PASS;

    // Parse IP header
    struct iphdr *ip = (void *)(eth + 1);
    if ((void *)(ip + 1) > data_end)
        return XDP_PASS;

    // Check for TCP protocol
    if (ip->protocol != IPPROTO_TCP)
        return XDP_PASS;

    // Parse TCP header
    struct tcphdr *tcp = (void *)(ip + 1);
    if ((void *)(tcp + 1) > data_end)
        return XDP_PASS;

    // Check for PostgreSQL port (5432)
    if (ntohs(tcp->dest) == 5432 || ntohs(tcp->source) == 5432) {
        // Allow PostgreSQL traffic
        return XDP_PASS;
    }

    // Drop all other traffic
    return XDP_DROP;
}
```

### 2.2 Validation Test Cases

| Test Case | Input | Expected Action | Verification |
|-----------|-------|-----------------|--------------|
| **TC-01** | TCP packet, dst=5432 | XDP_PASS | Packet reaches userspace |
| **TC-02** | TCP packet, src=5432 | XDP_PASS | Packet reaches userspace |
| **TC-03** | TCP packet, dst=80 | XDP_DROP | Packet dropped in kernel |
| **TC-04** | TCP packet, dst=443 | XDP_DROP | Packet dropped in kernel |
| **TC-05** | UDP packet, dst=5432 | XDP_PASS | UDP not filtered |
| **TC-06** | ICMP packet | XDP_PASS | Non-TCP not filtered |
| **TC-07** | Malformed TCP header | XDP_PASS | Safe fallback |
| **TC-08** | PostgreSQL SYN packet | XDP_PASS | Connection initiation allowed |
| **TC-09** | PostgreSQL FIN packet | XDP_PASS | Connection termination allowed |
| **TC-10** | Non-PostgreSQL TCP | XDP_DROP | All other TCP dropped |

### 2.3 Connection Tracking Validation

For stateful filtering (optional enhancement):

| State | Packet Type | Expected Action |
|-------|-------------|-----------------|
| NEW | SYN to 5432 | XDP_PASS |
| ESTABLISHED | ACK on 5432 connection | XDP_PASS |
| ESTABLISHED | Data on 5432 connection | XDP_PASS |
| INVALID | RST without connection | XDP_DROP |
| INVALID | ACK without SYN | XDP_DROP |

---

## 3. Throughput Testing Procedures

### 3.1 Test Environment Setup

#### Hardware Requirements
- **NIC:** 10 Gbps Ethernet (Intel X710, Mellanox ConnectX-5, or equivalent)
- **CPU:** 4+ cores, 2.5+ GHz
- **RAM:** 8 GB minimum
- **Storage:** SSD (for log files)

#### Software Requirements
- **Kernel:** Linux 5.10+ with XDP support
- **Tools:**
  - `xdp-loader` (from xdp-tools)
  - `pktgen` (kernel module)
  - `iperf3` (for application-level validation)
  - `bpftool` (for BPF program inspection)
  - `sar` / `mpstat` (for CPU monitoring)

#### Network Topology
```
[Generator] --10Gbps--> [DUT with XDP] --10Gbps--> [Receiver]
```

### 3.2 Test Procedure: Baseline Throughput

```bash
# 1. Load XDP program in PASS mode (no filtering)
sudo xdp-loader load -m skb eth0 xdp_pass.o

# 2. Configure pktgen for 64-byte packets
# (Use pktgen-dpdk or kernel pktgen)
# Example: 10 Mpps, 64-byte packets

# 3. Start traffic generation
# 4. Measure received packets on receiver
# 5. Record CPU usage with mpstat
mpstat 1 > baseline_cpu.log

# 6. Verify no packet loss
# Expected: ~10 Mpps received
```

### 3.3 Test Procedure: Filtered Throughput

```bash
# 1. Load PostgreSQL filter
sudo xdp-loader load -m native eth0 xdp_postgres_filter.o

# 2. Generate mixed traffic:
#    - 20% PostgreSQL (TCP:5432)
#    - 80% Other TCP (random ports)

# 3. Measure:
#    - Packets dropped by XDP (bpftool prog show)
#    - Packets passed to userspace
#    - CPU usage

# 4. Verify:
#    - All PostgreSQL packets passed
#    - All non-PostgreSQL TCP dropped
#    - Throughput >= 6 Mpps (minimum requirement)
```

### 3.4 Test Procedure: Multi-Core Scaling

```bash
# 1. Enable XDP multi-queue (RSS)
sudo ethtool -L eth0 combined 4

# 2. Load XDP program with CPU map
sudo xdp-loader load -m native eth0 xdp_postgres_filter.o \
    --map cpu_map

# 3. Generate traffic across multiple queues
# 4. Measure per-CPU statistics
bpftool prog show id <prog_id> --json | jq '.stats'

# 5. Verify near-linear scaling:
#    - 1 core: 6 Mpps
#    - 2 cores: 11 Mpps
#    - 4 cores: 20 Mpps
```

### 3.5 Test Procedure: Sustained Load

```bash
# 1. Run 24-hour sustained load test
# 2. Monitor:
#    - Memory leaks (bpftool map show)
#    - CPU drift (mpstat)
#    - Packet loss rate
# 3. Verify:
#    - No memory growth
#    - Stable CPU usage
#    - < 0.01% packet loss
```

---

## 4. Latency Measurements

### 4.1 Measurement Methodology

Use `ping` with microsecond precision and `tcptraceroute` for TCP latency:

```bash
# ICMP latency (baseline)
ping -i 0.001 -c 10000 <target_ip> > icmp_latency.log

# TCP latency to PostgreSQL
tcptraceroute -p 5432 <target_ip> > tcp_latency.log

# Extract percentiles
awk '{print $7}' icmp_latency.log | \
    sort -n | \
    awk 'BEGIN{c=0} {a[c++]=$1} END{print "50%:", a[int(c*0.5)]; \
    print "90%:", a[int(c*0.9)]; print "99%:", a[int(c*0.99)]}'
```

### 4.2 Latency Requirements

| Metric | Maximum | Target | Measurement |
|--------|---------|--------|-------------|
| **ICMP latency (no filter)** | 100 µs | 50 µs | ping |
| **ICMP latency (with filter)** | 150 µs | 100 µs | ping |
| **TCP handshake latency** | 200 µs | 150 µs | tcptraceroute |
| **Packet processing time** | 10 µs | 5 µs | bpf_trace_printk |
| **Tail latency (p99)** | 500 µs | 300 µs | percentile analysis |

### 4.3 Latency Impact Analysis

| Scenario | Baseline | With XDP | Overhead |
|----------|----------|----------|----------|
| No traffic | 0 µs | 0 µs | 0 µs |
| 1 Mpps | 20 µs | 25 µs | +5 µs |
| 5 Mpps | 50 µs | 70 µs | +20 µs |
| 10 Mpps | 100 µs | 150 µs | +50 µs |

---

## 5. Performance vs Security Trade-offs

### 5.1 XDP Modes Comparison

| Mode | Performance | Security | Use Case |
|------|-------------|----------|----------|
| **XDP_SKB** | Low (3-5 Mpps) | High | Compatibility mode |
| **XDP_DRV** | High (10-15 Mpps) | High | Native driver support |
| **XDP_OFFLOAD** | Very High (20+ Mpps) | High | NIC hardware offload |

**Recommendation:** Use `XDP_DRV` for production, fallback to `XDP_SKB` for unsupported NICs.

### 5.2 Filter Complexity vs Throughput

| Filter Type | Throughput | CPU Usage | Security Level |
|-------------|------------|-----------|----------------|
| **Port-only (5432)** | 9 Mpps | 30% | Basic |
| **Port + IP whitelist** | 7 Mpps | 45% | Medium |
| **Port + IP + connection tracking** | 5 Mpps | 60% | High |
| **Deep packet inspection** | 2 Mpps | 85% | Very High |

**Trade-off Analysis:**
- Port-only filtering provides best performance with basic security
- Connection tracking adds significant overhead but prevents spoofing
- Deep packet inspection is not recommended for XDP (use userspace instead)

### 5.3 Security Considerations

#### 5.3.1 Bypass Prevention

| Threat | Mitigation | Performance Impact |
|--------|------------|-------------------|
| **IP spoofing** | Connection tracking | -20% throughput |
| **Port hopping** | Dynamic port blocking | -10% throughput |
| **Protocol evasion** | Protocol validation | -15% throughput |
| **DoS amplification** | Rate limiting | -25% throughput |

#### 5.3.2 Fail-Safe Behavior

```c
// Always include safe fallback
SEC("xdp")
int postgres_filter(struct xdp_md *ctx) {
    // Parse headers with bounds checking
    if (parse_headers_failed) {
        // FAIL-SAFE: Pass to userspace for inspection
        return XDP_PASS;
    }

    // Apply filter logic
    if (is_postgresql_traffic) {
        return XDP_PASS;
    }

    return XDP_DROP;
}
```

**Rationale:** Better to pass suspicious traffic to userspace than to drop legitimate traffic.

### 5.4 Resource Limits

| Resource | Limit | Rationale |
|----------|-------|-----------|
| **Max connections tracked** | 10,000 | Prevent memory exhaustion |
| **Map entry TTL** | 300 seconds | Prevent stale entries |
| **Per-CPU packet buffer** | 256 packets | Prevent OOM |
| **BPF program complexity** | 1M instructions | Kernel verifier limit |

---

## 6. Test Automation

### 6.1 Automated Test Script

```bash
#!/bin/bash
# xdp_performance_test.sh

set -e

RESULTS_DIR="xdp_test_results_$(date +%Y%m%d_%H%M%S)"
mkdir -p "$RESULTS_DIR"

echo "Starting XDP Performance Test Suite"
echo "Results directory: $RESULTS_DIR"

# Test 1: Baseline throughput
echo "Test 1: Baseline throughput..."
./run_throughput_test.sh baseline > "$RESULTS_DIR/test1_baseline.log"

# Test 2: Filtered throughput
echo "Test 2: Filtered throughput..."
./run_throughput_test.sh filtered > "$RESULTS_DIR/test2_filtered.log"

# Test 3: Latency
echo "Test 3: Latency measurements..."
./run_latency_test.sh > "$RESULTS_DIR/test3_latency.log"

# Test 4: Multi-core scaling
echo "Test 4: Multi-core scaling..."
./run_scaling_test.sh > "$RESULTS_DIR/test4_scaling.log"

# Test 5: PostgreSQL validation
echo "Test 5: PostgreSQL filtering validation..."
./run_validation_test.sh > "$RESULTS_DIR/test5_validation.log"

# Generate report
echo "Generating test report..."
./generate_report.sh "$RESULTS_DIR" > "$RESULTS_DIR/report.md"

echo "Test suite complete. Report: $RESULTS_DIR/report.md"
```

### 6.2 CI/CD Integration

```yaml
# .github/workflows/xdp-performance.yml
name: XDP Performance Tests

on: [push, pull_request]

jobs:
  performance:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - name: Setup test environment
        run: ./scripts/setup_xdp_test_env.sh
      - name: Run performance tests
        run: ./scripts/xdp_performance_test.sh
      - name: Upload results
        uses: actions/upload-artifact@v3
        with:
          name: xdp-performance-results
          path: xdp_test_results_*/
      - name: Check thresholds
        run: ./scripts/check_performance_thresholds.sh
```

---

## 7. Success Criteria

The XDP filter implementation is considered **production-ready** when:

- [ ] **Throughput:** Achieves >= 6 Mpps with PostgreSQL filter active
- [ ] **Latency:** p99 latency <= 300 µs under 5 Mpps load
- [ ] **CPU:** CPU usage <= 50% at 5 Mpps
- [ ] **Validation:** All 10 test cases (TC-01 to TC-10) pass
- [ ] **Stability:** 24-hour sustained load with < 0.01% packet loss
- [ ] **Scaling:** Near-linear multi-core scaling (>= 80% efficiency)
- [ ] **Memory:** No memory leaks over 24-hour test
- [ ] **Fail-safe:** Malformed packets passed to userspace (not dropped)

---

## 8. Troubleshooting

### 8.1 Common Issues

| Issue | Symptom | Solution |
|-------|---------|----------|
| **Low throughput** | < 3 Mpps | Check NIC driver supports XDP_DRV |
| **High CPU** | > 80% at 5 Mpps | Optimize BPF program, reduce map lookups |
| **Packet loss** | > 1% loss | Increase ring buffer size, check IRQ affinity |
| **Memory leak** | Growing map size | Implement TTL for connection tracking |
| **Latency spikes** | p99 > 1 ms | Check for interrupt storms, enable RPS |

### 8.2 Debug Commands

```bash
# Check XDP program status
bpftool prog show

# View per-CPU statistics
bpftool prog show id <prog_id> --json | jq '.stats'

# Trace packet processing
bpftool prog tracelog

# Monitor dropped packets
sudo perf record -e xdp:xdp_exception -a
sudo perf script
```

---

## 9. References

- [XDP Tutorial](https://github.com/xdp-project/xdp-tutorial)
- [Linux XDP Documentation](https://www.kernel.org/doc/html/latest/networking/xdp-rx-metadata.html)
- [Cilium XDP Guide](https://docs.cilium.io/en/stable/bpf/#xdp)
- [Aya-rs Documentation](https://aya-rs.dev/)

---

**Document Version:** 1.0
**Last Updated:** 2026-02-24
**Owner:** eBPF Agent Team
**Status:** Draft
